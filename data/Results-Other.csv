Resultados ,,Descripcion,Enlace,Figuras,Informacion adicional
Publicaciones,,,http://oa.upm.es/cgi/search/advanced?screen=Public%3A%3AEPrintSearch&title_merge=ALL&title=&creators_name_merge=ALL&creators_name=&contributors_name_merge=ALL&contributors_name=&_fulltext__merge=ALL&_fulltext_=&abstract_merge=ALL&abstract=&keywords_merge=ALL&keywords=&subjects_merge=ALL&editors_name_merge=ALL&editors_name=&refereed=EITHER&publication_merge=ALL&publication=&event_title_merge=ALL&event_title=&note_merge=ALL&note=OEG&date=&satisfyall=ALL&order=-date%2Fcreators_name%2Ftitle&_action_search=Buscar,,
Ontologi­as,,,,,
Tecnologias y modelos,CIDER-CL,"CIDER-CL es un sistema para el alineamiento monolingue y multilingÃ¼e entre ontologÃ­as. Para ello utiliza varias medidas semÃ¡nticas como SoftTFIDF y Cross-Lingual Explicit Semantic Analysis. El cÃ¡lculo de diferentes similitudes semÃ¡nticas se combina mediante el uso de redes neuronales artificiales. CIDER-CL tiene dos modos de operar:
-Alineador de ontologÃ­as: toma dos ontologÃ­as en OWL como entrada y descubre sus equivalencias, que son ofrecidas como salida en formato RDF.
-Servicio de similitud semÃ¡ntica: toma dos entidades ontolÃ³gicas como entrada y da el valor numÃ©rico de la similitud semÃ¡tica entre ellos como salida. ",https://www.oeg-upm.net/files/cider-cl,,
Tecnologias y modelos,geometry2rdf,geometry2rdf es una librerÃ­a para generar ficheros RDF a partir de informaciÃ³n geomÃ©trica (que puede estar disponible en GML o WKT). La manipulaciÃ³n del GML y WKT se realiza con GeoTools. La version actual de la librerÃ­a trabaja con bases de datos geoespaciales y se basaa en Jena. geometry2rdf ha sido desarrollado por el equipo de GeoLinked Data (.es).,https://oeg.fi.upm.es/files/geometry2rdf/geometry2rdf_bin_0.0.3.zip,https://oeg.fi.upm.es/images/stories/tecnologias/geometry2rdf.png,"Quick start
Necesitas: Java 1.5 o superior en el path (comprueba con java -version si no estÃ¡s seguro)
Que hacer:
-Descargar y extraer los archivos a un directorio de trabajo.
-La distribuciÃ³n actual viene con un un fichero de propiedades de ejemplo.   Este fichero puede usarse como el fichero base con el que puedes empezar a trabajar.
-Ejecuta geometry2rdf desde lÃ­nea de comandos.
-Espera hasta que finalice, y comprueba el fichero rdf creado.
Trabajando con el fichero de configuraciÃ³n
La librerÃ­a necesita un fichero de propiedades para su ejecuciÃ³n. El nombre por defecto del fichero es options.properties. Se proporciona un fichero de pruebas con ese nombre en la distribuciÃ³n para us uso. Si quieres usar un fichero diferente, cambia la ruta del fichero de propiedades en el fichero bat.                                                                                                                        Estructura del fichero de propiedades:
1. Input and output parameters: Directorio de trabajo y nombre del fichero de salida.
2. DDBB parameters: Todos los parÃ¡metros necesarios para la conexiÃ³n con la BBDD se configuran en esta secciÃ³n. TambiÃ©n se configuran en esta secciÃ³n el nombre del tipo de recursos que se van a crear.
3. Namespaces parameters: En esta secciÃ³n se indican los namespaces y prefijos para los recursos generados y para la ontologÃ­a usada.
4. Reference systems parameters: Geometry2rdf funciona para sistemas de referencia EPSG. Si tus datos gml no estÃ¡n en EPGS, se necesita una transformaciÃ³n entres tu sistema de referencia y un sistema de referencia EPSG. Para ello, utiliza los campos fields gmlSourceRS y gmlTargetRS. Si se require o se desea alguna tranformaciÃ³n mÃ¡s para los datos en el fichero RDF resultante, utilice sourceRS and targetRS.
5. Types parameters: En esta secciÃ³n, se definen las URIs para los recursos Point, Linestring and Polygon. TambiÃ©n se define la URI de la relaciÃ³n ""formBy"". Un recurso Linestring y Polygon estÃ¡n ""formBy"" Points.
6. Other parameters: En esta secciÃ³n, se define el lenguaje por defecto de las etiquetas de cada recurso.                                       Ejemplos de ficheros RDF de salida.
AquÃ­ puedes consultar unos ejemplos de ficheros RDF de salida:
-Ejemplo de un recurso de tipo Municipio con geometrÃ­a formada por un Ãºnico punto. https://oeg.fi.upm.es/files/geometry2rdf/Point.rdf
-Ejemplo de un recurso de tipo Balsa con una geometrÃ­a de tipo Linestring. https://oeg.fi.upm.es/files/geometry2rdf/Linestring.rdf
-Ejemplo de un recurso de tipo Pozo con una geometrÃ­a de tipo Polygon. https://oeg.fi.upm.es/files/geometry2rdf/Polygon.rdf"
Tecnologias y modelos,gOntt,"gOntt es una herramienta para planificar y ejecutar proyectos de desarrollo cuyas principales caracterÃ­sticas son las siguientes:
-Hace uso de plantillas orientadas a la planificaciÃ³n de desarrollos de ontologÃ­as. Estos desarrollos se basan en los escenarios propuestos por la NeOn Methodology.
-Genera las planificaciones de proyectos de desarrollo de ontologÃ­as en forma de diagramas Gantt.
-Informa a los desarrolladores de ontologÃ­as sobre cÃ³mo llevar a cabo un proceso o una actividad haciendo uso de guÃ­as metodolÃ³gicas prescriptivas. TambiÃ©n informa sobre las herramientas especÃ­ficas de NeOn Toolkit que deben ser usadas.",http://neon-toolkit.org/wiki/Download,https://oeg.fi.upm.es/images/stories/tecnologias/gontt.png,"Funcionalidades de gOntt para la planificaciÃ³n de proyectos de desarrollo de ontologÃ­as.
gOntt ayuda a los desarrolladores de ontologÃ­as a decidir quÃ© ciclo de vida es el mÃ¡s apropiado para construir sus ontologÃ­as (cascada o incremental-iterativo) asÃ­ como quÃ© procesos y actividades deben llevarse a cabo y en quÃ© orden (por ejemplo, especificar los requisitos de la ontologÃ­a antes de proceder a la transformar un recurso de conocimiento en una ontologÃ­a). gOntt genera una representaciÃ³n grÃ¡fica de la planificaciÃ³n en forma de diagrama Gantt con los procesos y actividades requeridos, incluyendo las restricciones entre ellos. Las planificaciones de proyectos de desarrollo de ontologÃ­as pueden ser creadas desde cero (incluyendo procesos, actividades, fases y restricciones entre todos ellos) o de un modo guiado.
En el modo guiado, gOntt crea un plan preliminar para el desarrollo de la ontologÃ­a en forma de:
-Plantillas que generan automÃ¡ticamente la planificaciÃ³n inicial para proyectos de desarrollo de ontologÃ­as. Estas plantillas han sido construidas teniendo en cuenta la metodologÃ­a NeOn. Las plantillas contienen un plan por defecto basado en las diferentes posibles combinaciones que se pueden dar entre modelos de ciclos de vida y procesos y actividades.
-Un simple asistente en dos pasos que contiene preguntas intuitivas que permiten al desarrollador de ontologÃ­as seleccionar el modelo de ciclo de vida de las ontologÃ­as y los procesos y actividades necesarias para su desarrollo. Para contestar a tales preguntas el desarrollador de ontologÃ­as ha de tener en cuenta los requisitos de la ontologÃ­a y el tipo de recursos de conocimiento candidatos para ser reutilizados.
La principal salida de gOntt es el plan inicial para la construcciÃ³n de la ontologÃ­a en forma de diagrama Gantt que el desarrollador puede modificar con posterioridad ya sea: (a) incluyendo, modificando o borrando procesos, actividades y fases, (b) cambiando el orden y las dependencias entre procesos y actividades, e (c) incluyendo asignaciÃ³n de recursos y restricciones al plan. Esta funcionalidad de generar planes preliminares por defecto supone una gran ventaja sobre otras herramientas de planificaciÃ³n de proyectos.

Funcionalidades de gOntt para ayudar a la ejecuciÃ³n de proyectos
gOntt proporciona guÃ­as metodologÃ­as prescriptivas en forma de: (1) tarjetas que incluyen la definiciÃ³n de los procesos o actividades, sus objetivos, entradas, salidas, ejecutores de la acciÃ³n y momento de la ejecuciÃ³n, y (2) un flujo de trabajo que describe cÃ³mo debe ser llevado a cabo el proceso o la actividad, asÃ­ como sus entradas, salidas, tareas y actores involucrados. AdemÃ¡s, gOntt proporciona un acceso directo y automatizado a las herramientas de NeOn Toolkit asociadas a cada proceso y actividad. Complementariamente, gOntt muestra una guÃ­a de comienzo rÃ¡pido para cada herramienta lanzada.

CÃ³mo utilizar gOntt
Para usar gOntt, en primer lugar, se debe instalar NeOn Toolkit (http://neon-toolkit.org/wiki/Download), y despuÃ©s, el plugin gOntt.En el siguiente enlace (http://www.neon-project.org/nw/Movie:_gOntt) se muestra un vÃ­deo que muestra cÃ³mo usar gOntt."
Tecnologias y modelos,Kyrie,"Kyrie es un sistema de reescritura de consultas que usa una ontologÃ­a para reescribir una consulta Datalog en otra consulta Datalog que captura el conocimiento de la ontologÃ­a. La consulta reescrita obtiene extensionalmente de la fuente de datos los resultados (certain answers) que estÃ¡n implicados tanto extensionalmente como intensionalmente por la consulta original. En el caso de las consultas no recursivas es posible desplegar la consulta Datalog en una uniÃ³n de consultas conjuntivas, la cual puede ser posteriormente transformada a SQL u otros lenguajes, con otras herramientas como Morph.
Kyrie se iniciÃ³ como una derivaciÃ³n de REQUIEM. Los objetivos para este sistema han sido:
-mejorar los tiempos de reescritura
-producir consultas mÃ¡s cortas cuando sea posible, puesto que deberÃ­an suponer una carga computacional menor para los sistemas que aceptan las consultas reescritas
-mantener la lÃ³gica expresiva ELHIO para la descripciÃ³n de la ontologÃ­a
Estos objetivos han sido satisfechos como puede verse en la evaluaciÃ³n.",http://j.mp/benchmarkqueryrewriting,,"Las principales publicaciones referentes a este trabajo son las siguientes:
-Mora, JosÃ© and Corcho, Ã“scar. ""Engineering optimisations in query rewriting for OBDA"" I-SEMANTICS, 2013, 4-6 de septiembre 2013, Graz, Austria.
-Mora, J. & Corcho, O. (2013). Towards a systematic benchmarking of ontology-based query rewriting systems. The 12th International Semantic Web Conference (ISWC2013) (p./pp. 369--384), 21-26 de octubre 2013, Sydney, Australia."
Tecnologias y modelos,LabelTranslator,"LabelTranslator es un plug-in desarrollado dentro del proyecto NeOn. Este plug-in estÃ¡ implementado para la herramienta NeOn Toolkit y su funciÃ³n es la localizaciÃ³n de los elementos , clases y propiedades, de una ontologÃ­a en OWL creando un modelo repositorio lingÃ¼Ã­stico, llamado LIR por sus iniciales en inglÃ©s (Linguistic Information Repository).
El acceso multilingÃ¼e a las ontologÃ­as, hoy en dÃ­a, se exige por parte de las instituciones de todo el mundo con un gran nÃºmero de recursos disponibles en diferentes idiomas. Para resolver este problema, proponemos LabelTranslator, un plug-in que automÃ¡ticamente localiza ontologÃ­as. LabelTranslator toma como entrada una ontologÃ­a cuyas etiqueta se describen en un lenguaje natural fuente y obtiene la traducciÃ³n mÃ¡s probable en lenguaje natural destino. En total, el plug-in soporta las siguientes funcionalidades:
-Obtiene la traducciÃ³n mÃ¡s probable para cada etiqueta de la ontologÃ­a. LabelTranslator se basa en dos mÃ³dulos avanzados para esta tarea. El primer servicio, de traducciÃ³n, obtiene automÃ¡ticamente las diferentes traducciones posibles de una etiqueta de la ontologÃ­a mediante el acceso a diferentes recursos lingÃ¼Ã­sticos. Este servicio tambiÃ©n utiliza un mÃ©todo de composiciÃ³n con el fin de traducir las etiquetas compuestas (etiquetas formadas por varias palabras). El segundo mÃ³dulo, el ranking de las traducciones, ordena las diferentes traducciones de acuerdo a la similitud con su contexto lÃ©xico y semÃ¡ntico. El mÃ©todo se basa en una medida de relaciÃ³n sobre la base de glosas a la ambigÃ¼edad de las traducciones. Esto se realiza mediante la comparaciÃ³n de los sentidos asociados a cada posible traducciÃ³n y su contexto.
-Captura toda la informaciÃ³n lingÃ¼Ã­stica asociada con los conceptos utilizando un modelo lingÃ¼Ã­stico como repositorio (LIR). LIR, Repositorio de InformaciÃ³n LingÃ¼Ã­stica, es un modelo portÃ¡til que se puede asociar a cualquiera de los tÃ©rminos de una ontologÃ­a OWL a travÃ©s de un meta-ontologÃ­a OWL. Las clases principales que componen LIR (lexicalizaciÃ³n, sentido de la definiciÃ³n, contexto de uso, notas y procedencia) se organizan alrededor de la clase LexicalEntry, que estÃ¡ vinculado a  cada tÃ©rmino de la ontologÃ­a (por medio de la relaciÃ³n hasLexicalEntry). El conjunto de conceptos LIR permite una completa descripciÃ³n en lenguaje natural del tÃ©rmino de la ontologÃ­a al que estÃ¡ asociado. AdemÃ¡s, por medio de las tÃ­picas relaciones lÃ©xicas ya sea en el mismo idioma (por ejemplo, hasSynonym) a travÃ©s de idiomas (hasTranslation), LIR organiza la informaciÃ³n lingÃ¼Ã­stica en el mismo lenguaje natural y entre diferentes idiomas con el fin de proporcionar un conjunto multilingÃ¼e de informaciÃ³n que permita la localizaciÃ³n  de la ontologÃ­a.
-Utiliza un mecanismo de sincronizaciÃ³n para mantener la ontologÃ­a y la informaciÃ³n lingÃ¼Ã­stica sincronizada. La adiciÃ³n de nuevos tÃ©rminos en la ontologÃ­a o la supresiÃ³n de tÃ©rminos existentes se controla mediante el avanzado seguimiento de cambios (basado en los recursos Delta1) utilizado en NeOn Toolkit. Este mecanismo es capaz de captar los cambios aun cuando ontolÃ³gicamente hayan cambiado su posiciÃ³n en el modelo de la ontologÃ­a. Con la adopciÃ³n de esta funciÃ³n, LabelTranslator puede identificar con precisiÃ³n el conjunto mÃ­nimo de cambios necesarios para ajustar la estructura del modelo lingÃ¼Ã­stico, un paso crÃ­tico para asegurar que un cambio importante se haga  en la ontologÃ­a localizado.
Para descargar LabelTranslator, es necesario disponer de NeOn Toolkit que se puede descargar desde la pÃ¡gina principal del proyecto NeOn Toolkit. Una vez descargada la herramienta e instalada, mediante el update site que proporciona la herramienta, podrÃ¡ descargarse el plug-in LabelTranslator. La documentaciÃ³n de uso estÃ¡ disponible en la herramienta una vez descargado el plug-in e instalado.",,,
Tecnologias y modelos,LDP4j,"LDP4j es un framework de cÃ³digo abierto basado en Java para el desarrollo de aplicaciones de lectura y escritura de Linked Data basados en la especificaciÃ³n Linked Data Platform 1.0 (LDP) del W3C. LDP4j proporciona los componentes requeridos por los clientes y servidores para manejar sus comunicaciones basadas en LDP, ocultando la complejidad de los detalles del protocolo de los desarrolladores de aplicaciones y dejando que se centran en el desarrollo de su lÃ³gica de negocio especÃ­fica para su aplicaciÃ³n.",http://www.ldp4j.org/,,
Tecnologias y modelos,Lexical Model for ONtologies (lemon),"Lexical Model for ONtologies (lemon) es un modelo desarrollado colaborativamente en el proyecto Monnet y concebido para ser un estÃ¡ndar para el intercambio de informaciÃ³n lÃ©xica en la Web SemÃ¡ntica. lemon se basa en trabajo anterior de miembros de Monnet como los modelos LexInfo, LIR, y LM. El modelo lemon pretende ser un modelo: conciso, descriptivo (no prescritivo), modular, y basado en RDF.",http://lemon-model.net/,,
Tecnologias y modelos,LIR - Linguistic Information Repository,,,,
Tecnologias y modelos,map4rdf,"Recientemente, hemos visto un gran incremento en la cantidad de datos geoespaciales que estÃ¡n publicados utilizando RDF y los principios de Linked Data. Esfuerzos como el W3C Geo XG, y mÃ¡s recientemente la iniciativa GeoSPARQL estÃ¡n proporcionando los vocabularios necesarios para publicar este tipo de informaciÃ³n en la Web de Datos. map4rdf es un herramienta para explorar y visualizar conjuntos de datos RDF enriquecidos con informaciÃ³n geomÃ©trica.
map4rdf es un software open source que simplemente necesita ser configurado para usar cualquier SPARQL endpoint y que proporciona a los usuarios una visualizaciÃ³n de datos georreferenciados y en RDF en un mapa. Los aspectos geoespaciales de los datos se pueden modelar usando o el modelo de datos del W3C Geo XG o GeoSPARQL.",http://oeg-upm.github.io/map4rdf,,https://github.com/oeg-upm/map4rdf
Tecnologias y modelos,MARiMbA,"MARiMbA es una herramienta orientada a bibliotecas para transformar sus registros en formato MARC (MAchine-ReadableCataloging) a RDF, siguiendo las mejores prÃ¡cticas de Linked Data.
La herramienta soporta todo el proceso de asignaciÃ³n de correspondencias transformaciÃ³n entre los metadatos contenidos en los registros MARC y los vocabularios elegidos para generar RDF. Es una herramienta diseÃ±ada para facilitar el proceso de generaciÃ³n de Linked Data y permitir que sea llevado a cabo por el personal de las bibliotecas sin necesidad de asistencia tÃ©cnica. Para ello, MARiMbA ofrece las siguientes caracterÃ­sticas:
-EstÃ¡ probada para transformar registros de autoridad y bibliogrÃ¡ficos.
-Todo el trabajo se realiza a travÃ©s de hojas de cÃ¡lculo, no siendo necesario conocer el manejo de ningÃºn lenguaje de mapeo o transformaciÃ³n adicional (XML, XSLT, etc.)
-La herramienta realiza un anÃ¡lisis previo de los registros a transformar, generando las plantillas para las correspondencias a partir de dicho anÃ¡lisis. Dichas plantillas estÃ¡n enfocadas a mejorar la toma de decisiones del usuario, la identificaciÃ³n de errores y la evaluaciÃ³n del proceso de transformaciÃ³n.
-Permite usar cualquier vocabulario o mezcla de vocabularios en RDFS/OWL
-Incluye un fichero de configuraciÃ³n que permite realizar ajustes en la transformaciÃ³n. En cualquier caso, viene con una configuraciÃ³n por defecto que sigue el modelo FRBR (Functional RequirementsforBibliographicRecords).
-Incluye un servidor SPARQL ligero (Fuseki) que permite al usuario ejecutar
La herramienta ha sido utilizada con Ã©xito para realizar la transformaciÃ³n a RDF de cerca de 7 millones de registros MARC 21 de la Biblioteca Nacional de EspaÃ±a, y que ha dado como resultado alrededor de 60 millones de tripletas RDF. Los datos transformados son accesibles a travÃ©s de SPARQL en http://datos.bne.es/sparql. Por otro lado, un ejemplo de uno de los registros transformados es accesible en la siguiente direcciÃ³n: http://datos.bne.es/resource/XX1718747

",,,"Â¿CÃ³mo utilizarlo?
Necesitas:
-Registros MARC (autoridad y/o bibliogrÃ¡ficos) en formato ISO 2709
-Java 1.6 o superior en el path (comprueba con java -version si no estÃ¡s seguro)
-Un editor de hojas de cÃ¡lculo (OpenOffice, LibreOffice, Ms Excel, etc.)
Pasos:
1 Guardar/mover los ficheros MARC a transformar en la carpeta data. Poner los bibliogrÃ¡ficos en la carpeta data/bibliographic y los de autoridad en data/authority. Se pueden transformar tantos ficheros como se desee.
2 Ejecutar el comando que genera las plantillas de mapping: ""marimba --generatemappings -a -b""   Esta acciÃ³n genera 3 hojas de cÃ¡lculo: classificationMapping y annotationMapping, relationsMapping. AdemÃ¡s, crea una hoja de cÃ¡lculo adicional, alias, que permite asignar alias a aquellas clases y propiedades RDF mÃ¡s usadas para evitar utilizar la URI completa. Las hojas de cÃ¡lculo se encuentran por defecto en la carpeta mappings.
3 Utilizando las hojas de cÃ¡lculo generadas, asignar correspondencias entre las combinaciones encontradas en los registros MARC y las clases y propiedades de los vocabularios elegidos. Cada hoja de cÃ¡lculo tiene una funciÃ³n definida:
-classificationMapping: asignar la clase o tipo de recurso RDF a generar para cada una de las combinaciones.
-annotationMapping: asignar la propiedad RDF a generar a partir de cada uno de los subcampos.
-relationsMapping: asignar la relaciÃ³n RDF a establecer entre los recursos encontrados que presentan una determinada variaciÃ³n de subcampos.
4 Guardar en la carpeta models los ficheros RDF de los vocabularios utilizados. Para ello necesitas descargarlos de la Web o exportarlos a un fichero si estabas usando un editor de ontologÃ­as (como NeOnToolkit o ProtÃ©gÃ©).
5 Ejecutar el comando que genera RDF tomando las correspondencias, los registros y los vocabularios: ""marimba --generaterdf -a -b --writeresultado.rdf""
6 Si se quieren hacer consultas SPARQL directamente sobre los datos se puede ejecutar un servidor RDF ligero (Fuseki). Para ello se debe ejecutar: ""run-marimba-server""
Y en la direcciÃ³n http://localhost:3030/ se pueden hacer consultas sobre los datos generados"
Tecnologias y modelos,morph,"The morph suite of technologies (together with their corresponding algorithms), is focused on applying a range of query rewriting techniques over heterogeneous federated data sources, through the use of mappings expressed in the W3C R2RML language. The suite is composed of the following languages:
- morph-RDB, for accessing relational databases. Currently it provides support for relational database management systems such as mySQL, Postgres and MonetDB. (https://oeg.fi.upm.es/index.php/es/technologies/315-morph-rdb/index.html)
- morph-LDP, an extension of morph-RDB that works with our Linked Data Platform implementation [2]. (https://oeg.fi.upm.es/index.php/es/technologies/331-morph-ldp/index.html)
-morph-GFT, for accessing Google Fusion Tables. (https://oeg.fi.upm.es/index.php/es/technologies/316-morph-gft/index.html)
-morph-streams, for accessing data streams available in Esper, GSN or SNEE, although extensible for other dynamic data sources that expose data through a REST API. (https://oeg.fi.upm.es/index.php/es/technologies/320-morph-streams/index.html)
-SPARQL-DQP, for accessing federated SPARQL endpoints. (https://oeg.fi.upm.es/index.php/es/technologies/166-sparql-dqp/index.html)
-kyrie, for enriching SPARQL queries by considering ontology entailments. (https://oeg.fi.upm.es/index.php/es/technologies/314-kyrie/index.html)",,,
Tecnologias y modelos,morph-GFT,"morph-GFT is an extension of morph-RDB that works with Google Fusion Table (GFT) tables. These tables can be described using R2RML Mappings and enables users to query them using SPARQL. In morph-GFT, SPARQL queries posed by users are translated into SQL-like queries that are supported by the GFT API.
Unlike standard relational database implementations normally used with R2RML, the GFT API does not support join operations. Therefore, the SQL-like queries that can be evaluated directly over the GFT API are rather simple. For this reason, we use SPARQL-DQP [2] to perform joins of intermediate results and then these intermediate results are translated using the R2RML mappings specified by the users. Using SPARQL-DQP brings another benefit: not only can we join the intermediate results from GFT tables, but also from other SPARQL endpoints.            [1] Applying SPARQL-DQP for Federated SPARQL Querying over Google Fusion Tables, Freddy Priyatna, Carlos Buil Aranda, Oscar Corcho. Extended Semantic Web Conference (ESWC 2013) demo track. link
[2] Semantics and optimization of the SPARQL 1.1 federation extension, Carlos Buil Aranda, Marcelo Arenas, Oscar Corcho. Extended Semantic Web Conference (ESWC2011), Semantic Data Management track, 2011. Best paper award. link",https://github.com/oeg-upm/morph-gft,https://oeg.fi.upm.es/images/architecture-morphgft.png,The morph-GFT project page is located atÂ https://github.com/oeg-upm/morph-gftÂ and the instructions of how to use morph-GFT can be found atÂ https://github.com/oeg-upm/morph-gft/wiki
Tecnologias y modelos,morph-LDP,"morph-LDP[1] is an extension of morph-RDB that works with our Linked Data Platform implementation [2]. morph-LDP exposes relational data as read/write Linked Data for LDP-aware applications, whilst allowing legacy applications to continue using their relational databases.                                                                                                              [1] Mihindukulasooriya, N., Priyatna F., Corcho, O., GarcÃ­a-Castro, R. and Esteban-GutiÃ©rrez, M. morph-LDP: An R2RML-based Linked Data Platform implementation. The 11th Extended Semantic Web Conference 2014 Demo Session, Crete, Greece.
[2] Mihindukulasooriya, N., GarcÃ­a-Castro, R., Esteban-GutiÃ©rrez, M.: Linked Data Platform as a novel approach for Enterprise Application Integration. (Oct 2013)",https://oeg.fi.upm.es/images/stories/tecnologias/morph-ldp-scenario.png     https://oeg.fi.upm.es/images/stories/tecnologias/morph-ldp-1.png,,
Tecnologias y modelos,morph-RDB,"morph-RDB [1,3] (formerly called ODEMapster) is an RDB2RDF engine developed by the Ontology Engineering Group, which follows the R2RML specification (http://www.w3.org/TR/r2rml/). morph-RDB supports two operational modes:
-Data upgrade, which consists in generating RDF data from a relational database according to the R2RML mapping descriptions.
-Query translation, which allows evaluating SPARQL queries over a virtual RDF dataset, by rewriting those queries into SQL according to the R2RML mapping descriptions.
morph-RDB outperforms similar state-of-the-art tools (D2R) and query translation algorithms (e.g., the one proposed by Chebotko and colleagues in 2009) by employing various types of optimisations during the query rewriting process, so as to generate more efficient SQL queries. Some of these optimisations are self-join elimination, subquery elimination, and left-outer join elimination. morph-RDB has been tested with the BSBM synthetic benchmark and has been successfully deployed in various Spanish/EU projects (Integrate, RÃ©pener, and BizkaiSense) .
At the moment, morph-RDB works with relational database management systems like MySQL, PostgreSQL and MonetDB. In addition, morph-RDB has also been extended to support Google Fusion Tables in a project called morph-GFT [2] [6], and has been integrated with our Linked Data Platform implementation (LDP) [4] [5].
The morph-RDB project repository can be found at https://github.com/oeg-upm/morph-rdb and the instructions of how to use it can be found at https://github.com/oeg-upm/morph-rdb/wiki.

[1] Freddy Priyatna, Oscar Corcho, Juan Sequeda. Formalisation and Experiences of R2RML-based SPARQL to SQL query translation using Morph. World Wide Web Conference (WWW 2014). link
[2] Freddy Priyatna, Carlos Buil Aranda, Oscar Corcho. Applying SPARQL-DQP for Federated SPARQL Querying over Google Fusion Tables. Extended Semantic Web Conference (ESWC 2013) demo track. link
[3] Freddy Priyatna, Raul Alonso-Calvo, Sergio Paraiso, Gueton Padron-Sanchez and Oscar Corcho. R2RML-based access and querying to relational clinical data with morph-RDB. Semantic Web Applications and Tools for Life Sciences (SWAT 2015). (To appear)
[4] Mihindukulasooriya, N., GarcÃ­a-Castro, R., Esteban-GutiÃ©rrez, M.: Linked Data Platform as a novel approach for Enterprise Application Integration. (Oct 2013)
[5] Mihindukulasooriya, N., Priyatna F., Corcho, O., GarcÃ­a-Castro, R. and Esteban-GutiÃ©rrez, M. morph-LDP: An R2RML-based Linked Data Platform implementation. The 11th Extended Semantic Web Conference 2014 Demo Session, Crete, Greece.
[6] https://github.com/oeg-upm/morph-gft",https://github.com/oeg-upm/morph-rdb,,
Tecnologias y modelos,morph-streams,"morph-streams is an ontology-based data access system that allows evaluating SPARQL-Stream queries over a range of data streaming systems, which are mapped using the W3C R2RML language. More specifically, the current version of morph-streams provides wrappers for:
-The complex event processing engine Esper.
-The sensor network middleware GSN.
-The data stream management system SNEE.
Previous versions of morph-streams also supported the API of Pachube (now Xively), although this has been deprecated.
Morph-streams supports two modes of operation:
-It allows submitting SPARQL-Stream queries directly to an R2RML-wrapped data source. Queries are rewritten into the underlying query language or REST API and submitted to the underlying system, and results are then translated back using the same set of R2RML mappings.
-It allows registering SPARQL-Stream continuous queries over an R2RML-wrapped data source, to which consumers can subscribe, receiving updated results as soon as they are evaluated.
The morph-streams project repository can be found at https://github.com/oeg-upm/morph-streams, together with instructions on how to install it and use it. Besides, a live deployment of morph-streams with several types of streaming data sources can be found at http://streams.linkeddata.es/.",https://github.com/oeg-upm/morph-streams,,"An efficient RDF processing engine for heterogeneous data streams
The purpose of this research is to design and implement an engine that allows complex queries over heterogeneous data streams in near real-time at Web scale.
There is a growing number of applications that depend on the usage of real-time spatiotemporal data, and which allow moving from the usual three levels of decision making (strategic, tactical, and operational) to real-time decision making. One example would be real-time geomarketing, where decisions on offering discount coupons to customers may be made on really short time slots based on the combination of a set of spatiotemporal data streams coming from different providers, e.g. public transport card validations or weather information. Extracting information from these streams is complex because of the heterogeneity of the data, the rate of data generation, and the volume. To tap these data sources accordingly and get relevant information, scalable processing infrastructures are required, as well as approaches to allow data integration and fusion.
Our plan is to build a distributed stream processing engine capable of adapting to changing conditions while serving complex continuous queries. First, adapters for various formats are used to convert heterogeneous streams to Linked Data streams. Then, Adaptive Query Processing (AQP) allows adjusting the query execution plan to varying conditions of the data input, the incoming queries, and the system.
Our engine will address real-time processing following the Lambda principles. Lambda is a 3-layer architecture designed to alleviate the complexities of Big Data management: a batch layer stores all the incoming data in an immutable master dataset and pre-computes batch views; a serving layer indexes views on the master dataset; and a speed layer manages the real-time processing issues and requests data views depending on incoming queries. We will follow this design together with AQP techniques and RDF compressed data structures allowing to decrease access time in large datasets, as well as data transmission time among processing nodes.

 "
Tecnologias y modelos,OGSA-DAI RDF Resource,"OGSA-DAI RDF Resource es una extension al sistema de acceso a datos OGSA-DAI. Esta extensiÃ³n extiende OGSA-DAI aÃ±adiÃ©ndole un nuevo recurso de datos a los ya existentes en el framework (bases de datos relacionales, XML y archivos). Este nuevo recurso accede a datos en RDF almacenados en una base de datos RDF o accesibles mediante SPARQL endpoints. El acceso se realiza mediante el framework RDF Jena y Jena SDB. En la siguiente figura se muestra la extensiÃ³n dentro del contexto de OGSA-DAI. Esta imagen tambiÃ©n muestra otra extensiÃ³n a OGSA-DAI, la cual accede a un sistema RDB2RDF encargado de acceder a bases de datos relacionales mediante consultas a una ontologÃ­a.El nuevo recurso RDF es el encargado de configurar el acceso a los repositorios RDF. El acceso real lo realizan actividades complementarias a Ã©l. Estas actividades acceden al recurso, el cual configura los reursos de datos. Las actividades consultan posteriormente los recursos de datos y procesan los resultados de las consultas. Estos resultados son convertidos al formato interno de OGSA-DAI. Este formato son tuplas de la forma (calor1, valor2, Â…) y mediante este formato es posible integrar los resultados de otras consultas a otros recursos de datos de OGSA-DAI. El cÃ³digo del recurso puede descargarse del SVN de OGSA-DAI. Este recurso se utilice actualmente en el proyecto ADMIRE y tambiÃ©n es utilizado por el Sciences and Technologies Facilities Council  en el Reino Unido.",http://sourceforge.net/apps/trac/ogsa-dai/,https://oeg.fi.upm.es/images/stories/tecnologias/RDFResource1.png                   https://oeg.fi.upm.es/images/stories/tecnologias/RDFResource2.png,
Tecnologias y modelos,OOPS! Â– OntOlogy Pitfall Scanner!,"OOPS! es una aplicaciÃ³n web, independiente de cualquier entorno de desarrollo de ontologÃ­as, para detectar malas prÃ¡cticas en ontologÃ­as que podrÃ­an, potencialmente, provocar errores en el modelado de las mismas. El objetivo de esta herramienta es ayudar a los desarrolladores de ontologÃ­as durante la actividad de validaciÃ³n de las mismas, la cual puede dividirse en diagnÃ³stico y reparaciÃ³n. Actualmente, OOPS! proporciona mecanismos para detectar automÃ¡ticamente un nÃºmero de errores potenciales, ayudando por tanto a los desarrolladores durante la actividad de diagnÃ³stico.",http://oops.linkeddata.es/,https://oeg.fi.upm.es/images/stories/oops-1.png    https://oeg.fi.upm.es/images/stories/oops-2.png,"Â¿CÃ³mo usar OOPS!?
1)    Accede a http://oops.linkeddata.es/
2)    Introduce la URI de la ontologÃ­a a analizar o pega el cÃ³digo RDF en el cuadro de texto correspondiente (Ver Figura 1) y haz click en el botÃ³n asociado a cada opciÃ³n.
3)    Comprueba los resultados obtenidos (Ver Figura 2).
Contacto: oops@delicias.dia.fi.upm.es

 "
Tecnologias y modelos,Sem4Tags,"Sem4Tags es una herramienta multilingÃ¼e capaz de descubrir el significado de una etiqueta en un contexto dado y que como resultado ofrece un recurso DBpedia que define el significado de cada etiqueta procesada. La versiÃ³n actual soporta etiquetas en inglÃ©s y espaÃ±ol.
Sem4Tags identifica el significado de etiquetas multilingÃ¼es asociÃ¡ndoles recursos DBpedia. Este proceso tiene en cuenta el contexto de la etiqueta entendido como el conjunto de las etiquetas del usuario que coocurren cuando anotan un recurso. Sem4Tags usa un repositorio de significados multilingÃ¼e (MSR por sus siglas en inglÃ©s)  creado a partir de informaciÃ³n de la Wikipedia, donde cada palabra se relaciona con un conjunto de posibles significados que se han extraÃ­do de las pÃ¡ginas de desambiguaciÃ³n de Wikipedia.  Para seleccionar el significado mÃ¡s probable para una etiqueta, Sem4Tags utiliza un modelo de vectores que tiene en cuenta los tÃ©rminos que aparecen en cada una de las pÃ¡ginas Wikipedia que definen un significado.",http://grafias.dia.fi.upm.es/Sem4Tags/,,"Existe un servicio web disponible en la siguiente direcciÃ³n:http://grafias.dia.fi.upm.es/SemanticTagWebServiceRestFul/resources/tag/disambiguate
Existe una aplicaciÃ³n on-line disponible en la siguiente direcciÃ³n:http://grafias.dia.fi.upm.es/SemanticWebApp/DisambiguationTool.xhtml"
Tecnologias y modelos,sitemap4rdf,"Sitemap4rdf es una herramienta de lÃ­nea de comando que genera ficheros sitemap.xml para sitios de Linked Data que tienen un SPARQL endpoint. Sitemap4rdf consulta al endpoint y recupera una lista con todas las URLs, y genera el sitemap.xml, que debe ser subido al sitio web.

Entre sus caracterÃ­sticas, incluye soporte a la compresiÃ³n del Sitemap, y soporte para la particiÃ³n del Sitemap en varios ficheros para sitios de gran tamaÃ±o.",http://lab.linkeddata.deri.ie/2010/sitemap4rdf/,,
Tecnologias y modelos,SPARQL-DQP,"Este sistema implementa la extensiÃ³n para la federaciÃ³n de consultas de SPARQL 1.1, extendiendo el sistema OGSA-DAI/DQP. AdemÃ¡s, optimiza la ejecuciÃ³n de las consultas, trabajo realizado por SPARQL-DQP. Para ello, primero se identifican una serie de patrones bien diseÃ±ados (descritos en [1] and [2]) y si dichos patrones son identificados el sistema utiliza una serie de reglas de escritura que mejoran el tiempo de ejecuciÃ³n de las consultas.

[1] J. PÃ©rez, M. Arenas and C. Gutierrez, Semantics and complexity of SPARQL, TODS 34(3), 2009
[2] Semantics and optimization of the SPARQL 1.1 federation extension, Carlos Buil Aranda, Marcelo Arenas, Oscar Corcho. Extended Semantic Web Conference (ESWC2011), Semantic Data Management track, 2011. Best paper award. https://oeg.fi.upm.es/files/pdf/eswc11paper.pdf.
[3] Federating Queries in SPARQL1.1:Syntax, Semantics and Evaluation, Carlos Buil-Aranda, Marcelo Arenas, Oscar Corcho, Axel Polleres.http://www.websemanticsjournal.org/index.php/ps/article/view/321. ",http://videolectures.net/eswc2011_corcho_extension/,,
Tecnologias y modelos,vocab-express,"Hasta ahora, los principios y buenas prÃ¡cticas de Linked Data estÃ¡n siendo adoptadas por un nÃºmero creciente de proveedores de datos, teniendo como resultado una base de datos global en la Web que contiene cientos de conjuntos de datos LOD. En este contexto es importante promover la re-utilizaciÃ³n y enlazado de conjuntos de datos, y para este fin, es necesario conocer la estructura de los conjuntos de datos. Un primer paso para conocer la estructura de un conjunto de datos es explorar el vocabulario utilizado por el conjunto de datos, y como el conjunto de datos estÃ¡ utilizando ese vocabulario.
vocab-express es una herramienta simple para explorar el vocabulario utilizado en un conjunto de datos dado. La herramienta provee toda la informaciÃ³n relacionada del vocabulario:
1 la lista de todas las clases
2 la lista de todas las properties
3 el nÃºmero de instancias de cada clase
4 el nÃºmero de instancias de cada property
5 el lenguaje de las etiquetas y comentarios de los elementos del vocabulario.
vocab-express estÃ¡ siendo implementado en node.js, que es una plataforma construida sobre V8 (Google's open source JavaScript engine) para construir aplicaciones de red rÃ¡pidas y escalables. La figura muestra el flujo de informaciÃ³n de vocab-express.",,https://oeg.fi.upm.es/images/stories/tecnologias/vocab-express.jpg,
Tecnologias y modelos,NOR2O,"NOR2O ya no estÃ¡ siendo utilizado, ni es mantenido por el grupo.

NOR2O es una librerÃ­a para la transformaciÃ³n de recursos no ontolÃ³gicos en ontologÃ­as. Los recursos no-ontolÃ³gicos (NOR) son recursos de conocimiento cuya semÃ¡ntica no ha sido todavÃ­a formalizada en una ontologÃ­a. Hay una gran cantidad de NORs que incorporan conocimientos sobre algunos dominios particulares y que representan algÃºn grado de consenso.
En el contexto de la MetodologÃ­a NeOn, proponemos un mÃ©todo general para la re-ingenierÃ­a de recursos no-ontolÃ³gicos en ontologÃ­as. Se basa en  un patrÃ³n de re-ingenierÃ­a que define un procedimiento para transformar los componentes de un recurso no-ontolÃ³gico en primitivas de una ontologÃ­a, utilizando WordNet para desambiguar las relaciones implÃ­citas de los componentes del NOR.
La figura 1 muestra el diagrama de arquitectura de alto nivel conceptual de los mÃ³dulos implicados. El NOR connector carga los esquemas de clasificaciÃ³n, tesauros y lexicones con sus correspondientes modelos de datos e implementados en bases de datos, XML, ficheros de texto plano y hojas de cÃ¡lculo..
El Transformer lleva a cabo la transformaciÃ³n propuesta por los patrones. Este mÃ³dulo interactÃºa con el mÃ³dulo Semantic Relation Disambiguator para obtener la semÃ¡ntica de las relaciones de los elementos NOR.
El Semantic Relation Disambiguator se encarga de obtener la semÃ¡ntica de las relaciones entre dos elementos NOR. BÃ¡sicamente, el mÃ³dulo recibe dos elementos NOR del mÃ³dulo Transformer y devuelve la semÃ¡ntica entre ellos. El mÃ³dulo conecta el recurso externo a travÃ©s del mÃ³dulo External Resource Service para obtener la relaciÃ³n.
El External Resource Service  se encarga de interactuar con los recursos externos para obtener la semÃ¡ntica de las relaciones entre elementos NOR. Actualmente el mÃ³dulo interactÃºa con WordNet. Estamos implementando el acceso a DBpedia.
El OR Connector  genera la ontologÃ­a en OWL Lite. Para ello, utiliza la OWL API. Finalmente, para concluir la descripciÃ³n de la librerÃ­a de software, conviene mencionar que la implementaciÃ³n de esta librarÃ­a sigue un enfoque modular, por lo tanto, es posible extenderla para incluir otros tipos de NOR, modelos de datos e implementaciones de una manera sencilla, asÃ­ como la explotaciÃ³n de otros recursos externos para la desambiguaciÃ³n de relaciones.",,https://oeg.fi.upm.es/images/stories/tecnologias/nor2o.png,
Tecnologias y modelos,ODESeW,"ODESeW ya no estÃ¡ siendo utilizado ni mantenido por nuestro grupo.

ODESeW (Semantic Web Portal based on WebODE platform) es una aplicaciÃ³n basada en ontologÃ­as que genera automÃ¡ticamente y gestiona portales de conocimiento para intranets y extranets. ODESeW estÃ¡ construido dentro de la plataforma de ingenierÃ­a de ontologÃ­as WebODE y provee las siguientes funcionalidades:
-Modela conocimiento mediante una plataforma de desarrollo de ontologÃ­as que entregra un conjunto de servicios de desarrollo de ontologÃ­as. AsÃ­ como el portal de conocimiento se va a usar en la web, es altamente recomendado que use un servidor de ontologÃ­as (y no un editor de ontologÃ­as ejecutado de forma aislada) que permita construir ontologÃ­as de forma colaborativa asÃ­ como dar acceso a los ontologÃ­as mediante internet. La construcciÃ³n del portal sobre un servidor de ontologÃ­as facilita la sincronizaciÃ³n de la informaciÃ³n acorde a los cambios de las ontologÃ­as. Desde una perspectiva software, el portal se beneficia de los servicios presentes y futuros del servidor de ontologÃ­as.
-EdiciÃ³n e inserciÃ³n de contenido mediante ediciÃ³n de instancias de ontologÃ­as. ODESeW permite insertar, actualizar y borrar instancias de clases, sus atributos y sus relaciones en una red de ontologÃ­as interrelacionadas y con diferentes permisos de ediciÃ³n para los usuarios del portal. Como parte de la ediciÃ³n de instancias, ODESeW puede ser utilizado como una herramienta de gestiÃ³n documentacional en la que permite manejar documentos electrÃ³nicos.
-VisualizaciÃ³n de contenido mediante visualizaciones para los usuarios de ontologÃ­as, relaciones e instancias altamente configurables. La ontologÃ­as es utilizada como Ã­ndice de la informaciÃ³n insertada y para navegar atreves de esta. El contenido almacenado en el portal puede ser accedido dinÃ¡micamente mediante minuÃ©s generados por las ontologÃ­as acorde a los permisos del usuario, visualizando asÃ­ las distintos tipos de informaciÃ³n introducidos en el portal. El portal de conocimientos tambiÃ©n provee anotaciÃ³n de su contenido en RDF(S), , DAML+OIL y OWL.
-BÃºsqueda y consultas del contenido basada en una aproximaciÃ³n hÃ­brida entre ontologÃ­as y bÃºsqueda por palabras. El modulo de bÃºsquedas y consultas utiliza al interfaz de acceso de WebODE para acceder y consultar contenido de las ontologÃ­as.
-Servicios que facilitan la administraciÃ³n, que permiten gestionar los usuarios del portal, los permisos de ediciÃ³n y visualizaciÃ³n, otros elementos de gestiÃ³n del portal. Estos servicios puede ser solamente accedidos por aquellos usuarios que pertenecen al grupo de administraciÃ³n del portal.
-Como una ventaja importante de ODESeW frente a otros portales de conocimiento similares es la automÃ¡tica sincronizaciÃ³n del portal y de las ontologÃ­as en las que se basa. AsÃ­, si una ontologÃ­a es modificada dentro del editor de ontologÃ­as WebODE, los cambios se ven automÃ¡ticamente reflejados en el portal, tanto como la conceptualizaciÃ³n misma de la ontologÃ­as como de sus instancias.",,,
Tecnologias y modelos,OWLDoc,"OWLDoc es un plug-in desarrollado dentro del proyecto NeOn. Este plug-in estÃ¡ implementado para la herramiento NeOn Toolkit y su funciÃ³n es aÃ±adir una opciÃ³n al menÃº de exportaciÃ³n de la herramienta para generar documentos HTML a partir de una ontology OWL.
El plug-in utiliza el OWL API para extrar la informaciÃ³n de la ontologÃ­a OWL y crear una salida que contiene, de manera organizada, un conjunto de ficheros HTML que proporcionan la documentaciÃ³n acerca de la ontologÃ­a y todos sus recursos.
Para descargar OWLDoc, es necesario disponer de NeOn Toolkit que se puede descargar desde la pÃ¡gina principal del proyecto NeOn Toolkit. Una vez descargada la herramienta e instalada, mediante el update site que proporciona la herramienta, podrÃ¡ descargarse el plug-in OWLDoc. La documentaciÃ³n de uso estÃ¡ disponible en la herramienta una vez descargado el plug-in e instalado.",,,
Tecnologias y modelos,R2O y ODEMapster,"R2O & ODEMapster ya no estÃ¡ siendo utilizado, ni realizamos mantenimiento alguno en el grupo, puesto que ha sido reemplazado por el paquete de herramientas morph, que incluye morph-RDB, morph-GFT y morph-streams.
R2O & ODEMapster es un marco integrado para la expresiÃ³n formal, la evaluaciÃ³n, verificaciÃ³n y explotaciÃ³n de correspondencias semÃ¡nticas entre ontologÃ­as y bases de datos relacionales. El marco integrado estÃ¡ compuesto por:
-R2O, un lenguaje formal declarativo con expresividad suficiente como para representar situaciones de correspondencia complejas debidas al hecho de que se alinean dos modelos desarrollados y mantenidos de forma independiente y entre los que pueden darse disparidades de todo tipo.
-ODEMapster, procesador que se encarga del proceso de upgrade o enriquecimiento semÃ¡ntico del contenido de la base de datos o mediante la extracciÃ³n bajo demanda del contenido de la base de datos en respuesta a preguntas planteadas en tÃ©rminos de la ontologÃ­a mediante un proceso de re-escritura de consultas.
Por otro lado, ODEMapster plugin, desarrollado dentro el contexto del proyecto NeOn, proporciona una interfaz grÃ¡fica que permite crear, ejecutar o realizar consultas de ""mappings"" R2O. Este plugin estÃ¡ incuido en el NeOn Toolkit.
Para utilizar ODEMpaster plugin, primero hay que instalar NeOn Toolkit. NeOn Toolkit puede descargarse desde www.neon-toolkit.org. Una vez descargado, ejecute el fichero y siga las instrucciones.
DespuÃ©s de instalar NeOn Toolkit, el siguiente paso es instalar ODEMapster plugin. Este paso se puede realizar mediante las siguientes acciones:
1 Abrir Neon Toolkit.
2 Desde el menÃº Help de Neon Toolkit, elegir Â“Software UpdatesÂ” --> Â“Find and InstallÂ”.
3 Una ventana Install/Update aparecerÃ¡ en Neon Toolkit.
-Si ha instalado este plugin anteriormente, selecciones: Â“Search for updateÂ”
-Si no ha instalado este plugin anteriormente, seleccione: Â“Search for new featuresÂ”
-Seleccione Â“Neon Toolkit Update SiteÂ” entre los posibles sitios de actualizaciÃ³n y pulse finish
-Seleccione Â“ODEMapsterÂ” dentro de Â“Ontology PopulationÂ” y presione next
-Seleccione Â“AgreeÂ” en el acuerdo de licencia.
-Pulse Â“FinishÂ” en la ventana de instalaciÃ³n..
Para una informaciÃ³n mÃ¡s completa, consulte el manual de ODEMapster. http://geo.linkeddata.es/c/document_library/get_file?uuid=2a944333-4cd6-4ff1-aaab-68f62fbf0d3c&groupId=10136
 Â¿CÃ³mo funciona?
Para la ontologÃ­a hydrOntology y cada una de las bases de datos del IGN se creÃ³ un documento R2O que describe los mappings entre cada base de datos y la ontologÃ­a. A continuaciÃ³n, se ejecutÃ³ el procesador ODEMapster para generar las instancias RDF.  Las bases de datos del IGN estÃ¡n almacenadas en MySQL y ORACLE e hydrOntology estÃ¡ en OWL.",,https://oeg.fi.upm.es/images/stories/odemapsterprocess.png   https://oeg.fi.upm.es/images/stories/igndatasets.png,"Lista de usuarios de ODEMapster
FAO - http://fao.org
Guntars Bumars - University of Latvia - Institute of Mathematics and Computer Science - http://www.lumii.lv/Pages/computer.htm
Christian M. Fletcher - Department of Computer Science - Durham University - http://www.dur.ac.uk/ecs/computing.science/undergraduate09/whatis/
iSOCO - www.isoco.com
GIS4GOV project
SemSorGrid4Env - http://www.semsorgrid4env.eu/
GeoLinkedData - http://geo.linkeddata.es/
WEB n+1 - http://www.webenemasuno.es"
Tecnologias y modelos,WebODE,"WebODE ya no estÃ¡ siendo utilizado ni mantenido por nuestro grupo desde 2006.

WebODE es un suite extensible de ingenierÃ­a de ontologÃ­as basada en un servidor de aplicaciones que empezÃ³ en 1999. El nÃºcleo de WebODE es su servicio de acceso a sus ontologÃ­as, utilizado por todos los demÃ¡s servicios y aplicaciÃ³n acopladas al servidor. El editor de ontologÃ­as WebODE permite editar y navegar por las ontologÃ­as, y esta basada en formularios HTML y applets de Java.

WebODE fue construido como una plataforma escalable, extensible e integrada que cubre y da soporte a la mayorÃ­a de las actividades involucradas en el proceso de desarrollo de ontologÃ­as (conceptualizaciÃ³n, razonamiento, intercambio, etc.) y provee un conjunto de servicios relaciones a las ontologÃ­as que permite interoperar con otros sistemas de informaciÃ³n. Entre estos servicios, la plataforma integra servicios para la importaciÃ³n y exportaciÃ³n de lenguajes de ontologÃ­as (XML, RDF(S), OIL, DAML+OIL, OWL, CARIN, FLogic, Jess, Prolog), para la ediciÃ³n de axiomas mediante WAB (WebODE Axiom Builder), para generar documentaciÃ³n, para evaluar, para controlar la evoluciÃ³n, para extraer ontologÃ­as, para juntarlas y un motor de inferencia.

La publicaciÃ³n mÃ¡s relevante es Most relevant publications:

WebODE in a nutshell. AI Magazine 2003.",,https://oeg.fi.upm.es/images/stories/tecnologias/webode.png,
Tecnologias y modelos,WS-DAIOnt-RDF(S),"WS-DAIOnt-RDF(S) ya no estÃ¡ siendo utilizado ni mantenido por nuestro grupo.

WS-DAIOnt-RDF(S) es una especificaciÃ³n que define un mecanismo de acceso a ontologÃ­as RDF(S) utilizando una aproximaciÃ³n orientada a servicios. Esta especificaciÃ³n, compatible con la arquitectura OGSA, define el conjunto de recursos de datos, mensajes e interfaces de acceso necesarios para la integraciÃ³n de ontologÃ­as en RDF (S) en cualquier aplicaciÃ³n (Grid) orientada a servicios.  RDF(S) Grid Access Bridge  (RGAB) es la implementaciÃ³n de referencia de dicha especificaciÃ³n. Esta implementaciÃ³n desacopla el mecanismo de acceso de la ubicaciÃ³n fÃ­sica real de las ontologÃ­as RDF(S) asÃ­ como del sistema de almacenamiento utilizado para su persistencia.
De esta forma, las ontologÃ­as RDF (S) pueden ser almacenadas en un conjunto distribuido de sistemas de almacenamiento de RDF (S) y hacerse accesibles mediante los mecanismos de acceso definidos por la especificaciÃ³n WS-DAIOnt-RDF (S).",,,
Servicios,esDBpedia,"DBpedia ocupa un lugar central  en la Web de Datos por el importante volumen de datos semÃ¡nticos que proporciona a partir de la informaciÃ³n contenida en los infoboxes (Fichas en espaÃ±ol) de la Wikipedia del idioma inglÃ©s. La Ãºltima versiÃ³n de DBpedia (v3.9, septiembre de 2013) proporciona datos semÃ¡nticos de 4 millones de entidades, de las que 3.2 millones estÃ¡n clasificadas conforme a la ontologÃ­a DBpedia: Personas (832 mil),  Lugares (639 mil), Discos musicales (116 mil), y un largo etcÃ©tera (529 claes y 2333 propiedades).
A partir de los 30 millones de artÃ­culos en 240 idiomas que almacena Wikipedia (4.4 millones en inglÃ©s, 1.1 millones en espaÃ±ol), DBpedia genera 2460 millones datos semÃ¡nticos (tripletas RDF) en 119 idiomas (470 millones en inglÃ©s, y 100 millones en espaÃ±ol).
Hasta julio de 2011 (versiones DBpedia anteriores a la v3.7), sÃ³lo se extraÃ­a informaciÃ³n de una pÃ¡gina en espaÃ±ol de la Wikipedia si se apuntaba a ella desde la versiÃ³n inglesa. Por tanto, muchas pÃ¡ginas con informaciÃ³n local relevante (e.g. pueblos, rÃ­os, organizaciones) a la que no se podÃ­a llegar desde la versiÃ³n inglesa de Wikipedia, quedaban fuera del proceso de extracciÃ³n de DBpedia. En julio de 2011, la versiÃ³n 3.7 de DBpedia se construyÃ³ usando un nuevo mecanismo de extracciÃ³n que rompÃ­a con la dependencia de la versiÃ³n inglesa de Wikipedia, permitiendo generar, adicionalmente, informaciÃ³n semÃ¡ntica a partir de las versiones de Wikipedia en 15 idiomas, entre ellos el espaÃ±ol (ca, de, el, es , fr, ga, hr, hu, it, nl, pl, pt, ru, sl, tr). La versiÃ³n 3.8 de DBpedia (junio 2012) ampliÃ³ la lista de idiomas a 111, y la versiÃ³n actual (3.9) llegÃ³ a los 119 idiomas.

Jornadas de mapeos
Sin embargo, para que la Web de Datos se enriquezca con la informaciÃ³n contenida en la versiÃ³n espaÃ±ola de la Wikipedia, es necesario un esfuerzo colectivo importante a fin de aumentar el nÃºmero de mapeos de Fichas. DBpedia pone a disposiciÃ³n de la comunidad herramientas web para editar estos mapeos en los que se indica la correspondencia entre tÃ©rminos de las Fichas y los tÃ©rminos de la ontologÃ­a de DBpedia. La I Jornada esDBpedia  logrÃ³ mapear el 80% de los datos de la wikipedia del idioma espaÃ±ol y permitiÃ³ la creaciÃ³n de es.dbpedia.org, el capÃ­tulo espaÃ±ol de DBpedia en mayo de 2012. La II ediciÃ³n de las jornadas (diciembre de 2012) se centrÃ³ en mejorar la calidad de los mapeos.",,,
Metodologi­as,La MetodologÃ­a NeOn,"La MetodologÃ­a NeOn para la construcciÃ³n de redes de ontologÃ­as es una metodologÃ­a basada en escenarios que se apoya en los aspectos de colaboraciÃ³n de desarrollo de ontologÃ­as y la reutilizaciÃ³n, asÃ­ como en la evoluciÃ³n dinÃ¡mica de las redes de ontologÃ­as en entornos distribuidos. Las claves de la MetodologÃ­a NeOn son:
-Un conjunto de nueve escenarios para la construcciÃ³n de ontologÃ­as y redes de ontologÃ­as, haciendo hincapiÃ© en la reutilizaciÃ³n de los recursos ontolÃ³gicos y no ontolÃ³gicos, la reingenierÃ­a y la fusiÃ³n, y teniendo en cuenta la colaboraciÃ³n y el dinamismo.
-El Glosario de Procesos y Actividades identifica y define aquellos procesos y actividades involucrados en el desarrollo de redes de ontologÃ­as.
-Directrices metodolÃ³gicas para diferentes procesos y actividades del proceso de desarrollo de la ontologÃ­a de la red, tales como la reutilizaciÃ³n y la reingenierÃ­a de los recursos ontolÃ³gicos y no ontolÃ³gicos, la especificaciÃ³n de los requisitos de la ontologÃ­a, la localizaciÃ³n de la ontologÃ­a, la programaciÃ³n, etc. Todos los procesos y actividades se describen con (a) una tarjeta llena, (b) un flujo de trabajo, y (c) ejemplos.

Escenario 1: Desde la especificaciÃ³n de la aplicaciÃ³n. La red de ontologÃ­as se desarrolla a partir de cero (sin volver a utilizar los recursos existentes). Los desarrolladores deben especificar los requisitos de la ontologÃ­a (enlace a las directrices). DespuÃ©s de eso, se asesora para llevar a cabo una bÃºsqueda de recursos potenciales para ser reutilizados. A continuaciÃ³n, la actividad de planificaciÃ³n se debe realizar (enlace a las directrices), y los desarrolladores deben seguir el plan.
Escenario 2: La reutilizaciÃ³n y reingenierÃ­a de los recursos no ontolÃ³gicosc (NOR). Los desarrolladores deben llevar a cabo el proceso de reutilizaciÃ³n NOR para decidir, de acuerdo con los requisitos de la ontologÃ­a, que NORs pueden ser reutilizados para construir la red de la ontologÃ­a. A continuaciÃ³n, los NORs seleccionados deben ser volver al proceso de re-ingenierÃ­a ontolÃ³gicas. Las directrices se presentan en el enlace de directrices.
Escenario 3: La reutilizaciÃ³n de los recursos ontolÃ³gicos. Los desarrolladores utilizan recursos ontolÃ³gicos (ontologÃ­as como un conjunto de mÃ³dulos ontolÃ³gicos (enlace a las directrices enlace 1, enlace 2), y / o declaraciones ontolÃ³gicas (enlace a las directrices)) para construir redes de ontologÃ­as.
Escenario 4: La reutilizaciÃ³n y re-ingenierÃ­a de los recursos ontolÃ³gicos. Los desarrolladores de ontologÃ­as reutilizan los recursos y reorganizar los recursos  ontolÃ³gicos.
Escenario 5: La reutilizaciÃ³n y la fusiÃ³n de los recursos ontolÃ³gicos. Este escenario se produce cuando varios recursos ontolÃ³gicos en el mismo dominio que se seleccionan para su reutilizaciÃ³n, y los desarrolladores desean crear un nuevo recurso ontolÃ³gico con los recursos seleccionados. Las directrices se presentan en el enlace de directrices.
Escenario 6: ReutilizaciÃ³n, la fusiÃ³n y re-ingenierÃ­a de los recursos ontolÃ³gicos. Los desarrolladores de ontologÃ­as reutilizan, combinan y reorganizan los recursos-ontolÃ³gicos. Este escenario es similar al Escenario 5, pero en este caso los desarrolladores deciden reorganizar el conjunto de recursos combinados.
Escenario 7: ReutilizaciÃ³n de los patrones de diseÃ±o de ontologÃ­as (ODPs). Los desarrolladores de ontologÃ­as acceden a repositorios de reutilizaciÃ³n ODPs.
Escenario 8: ReestructuraciÃ³n de recursos ontolÃ³gicos. Los desarrolladores de ontologÃ­as reestructuran (modularizan, podan, extienden y / o especializan) recursos ontolÃ³gicos que deben integrarse posteriormente en la red de ontologÃ­as.
Escenario 9: LocalizaciÃ³n de recursos ontolÃ³gicos. Los desarrolladores de ontologÃ­as adaptan una ontologÃ­a a otras lenguas y la cultura las comunidades, obteniendo asÃ­ una ontologÃ­a multilingÃ¼e. Las directrices se presentan en el enlace de directrices.",http://oa.upm.es/3879/,https://oeg.fi.upm.es/images/stories/tecnologias/neonmethodology.png,
Linked data,LinkedData.es,"LinkedData(.es) es una sitio web en el que se pueden consultar, de una manera rÃ¡pida, las iniciativas, proyectos, colaboraciones y aplicaciones desarrolladas por el grupo en el Ã¡mbito de los Datos Enlazados. Como se puede observar, el grupo ha desarrollado y sigue desarrollando trabajos en diferentes dominios (geogrÃ¡fico, cultural, datos abiertos etc) tanto con instituciones pÃºblicas (BNE, RTVE, IGN, etc) como con empresas privadas (Grupo PRISA). TambiÃ©n nos encargamos de la DBpedia en espaÃ±ol, esDBpedia. ",http://linkeddata.es/,,
Linked data,GeoLinked Data,"GeoLinked Data (.es) es una iniciativa para el enriquecimiento de la Web de los Datos con datos geoespaciales del territorio nacional espaÃ±ol. Esta iniciativa se puso en marcha en el aÃ±o 2008 con la publicaciÃ³n de diversas fuentes de informaciÃ³n geogrÃ¡fica procedentes del Instituto GeogrÃ¡fico Nacional espaÃ±ol, haciÃ©ndolas disponibles como bases de conocimiento RDF (Resource Description Framework) conforme a los principios de Linked Data.
De esta manera, EspaÃ±a se sumaba en dicho momento a la iniciativa que otros paÃ­ses como el Reino Unido habÃ­an comenzado tambiÃ©n.
Algunos de los productos que se obtuvieron como resultado de este trabajo fueron los siguientes:
-geometry2rdf, una librerÃ­a para la generaciÃ³n de RDF geogrÃ¡fico. Esta librerÃ­a fue utilizada como base para la generaciÃ³n de la librerÃ­a TripleGeo, que se ha utilizado para la generaciÃ³n de RDF geogrÃ¡fico de un gran nÃºmero de fuentes de datos geogrÃ¡ficas europeas.
-map4RDF, para la visualizaciÃ³n de datos geogrÃ¡ficos enlazados, disponibles en un punto de acceso SPARQL.
Desde entonces, desde nuestro grupo hemos continuado trabajando en la mejora de estas herramientas, con el objetivo de ofrecer un conjunto de sistemas que puedan ser utilizados para la generaciÃ³n de RDF geogrÃ¡fico, de acuerdo con las lecciones aprendidas por la comunidad internacional en estos primeros pasos, asÃ­ como teniendo en cuenta los principales resultados del grupo de trabajo del W3C sobre Spatial Data on the Web.
AsÃ­, hemos trabajado en crear un plugin para GeoKettle que hace uso y extiende la librerÃ­a TripleGeo, y en estos momentos (aÃ±o 2017), estamos trabajando en la reediciÃ³n de una nueva versiÃ³n del portal de datos geogrÃ¡ficos y de Linked Data GeogrÃ¡fico, basado en la base de datos BTN100, que incorpora todos estos avances realizados en los Ãºltimos aÃ±os. La descripciÃ³n de este portal se actualizarÃ¡ una vez que se haya desplegado esta nueva versiÃ³n a finales del aÃ±o 2017.",,,
Material utilizado en artÃ­culos,Detecting common scientific workflow fragments using templates and execution provenance,"La evaluaciÃ³n del artÃ­culo ""Detecting common scientific workflow fragments using templates and execution provenance"" aceptado en K-CAP 2013 se encuentra disponible en el siguiente link. Los datos expuestos consisten en los grafos que se han utilizado como entrada para el experimento (derivados del SPARQL endpoint pÃºblico de Wings), los resultados y logs obtenidos por el algoritmo SUBDUE durante su ejecuciÃ³n y algunas estadÃ­sticas y hojas excel resumiendo dichos resultados (por ejemplo, destacando el  nÃºmero de estructuras que son independientes, contando aquellas que son relevantes, etc.).

Si estÃ¡ interesado en obtener mÃ¡s informaciÃ³n puede leer el siguiente artÃ­culo: Daniel Garijo, Oscar Corcho y Yolanda Gil. Detecting common scientific workflow fragments using templates and execution provenance. K-CAp 2013, Banf, Canada.",https://www.oeg-upm.net/files/dgarijo/kcap2013Eval,,
Material utilizado en artÃ­culos,Semantic Grounding of Tags (sem4tags),"Se publican los datos de la evaluaciÃ³n de las asociaciones de entidades semÃ¡nticas producidas por sem4tags y sus variaciones para las etiquetas extraÃ­das de Flickr (link a conjunto de datos).  Las evaluaciones estÃ¡n en un archivo CSV donde los diferentes campos que componen la evaluaciÃ³n estÃ¡n separados por el carÃ¡cter Â“|Â”. Cada fila en este archivo representa una evaluaciÃ³n individual de la asociaciÃ³n de una entidad semÃ¡ntica a una etiqueta. Recuerde que cada asociaciÃ³n semÃ¡ntica fue evaluada por al menos tres evaluadores. Finalmente, se recomienda leer el archivo readme donde se explica en detalle cada uno de los atributos que describen cada evaluaciÃ³n. Para cualquier duda acerca de este conjunto de datos se puede contactar a AndrÃ©s GarcÃ­a-Silva",,,
Material utilizado en artÃ­culos,Characterising Emergent Semantics in Twitter Lists,"El siguiente conjunto de datos contiene los datos de las listas de Twitter que han sido utilizados en los experimentos presentados en el artÃ­culo ""Characterising Emergent Semantics in Twitter Lists"" del 9th Extended Semantic Web Conference (ESWC 2012). Los datos se encuentran en una archivo de respaldo de una base de datos mysql version 5.5.14 que contiene informaciÃ³n de las listas y de los distintos tipos de usuarios que interactÃºan con ellas. AdemÃ¡s hemos incluido un diagrama entidad relaciÃ³n que representan las tablas que contienen la informaciÃ³n.
Por favor si usted usa este conjunto de datos cite la siguiente referencia: GarcÃ­a-Silva A., Kang J.H., Lerman K and Corcho O. Characterising Emergent Semantics in Twitter Lists. In proceedings of the 9th extended Semantic Web Conference ESWC, Crete, 2012.
Para preguntas sobre el conjunto de dato, contacte con: AndrÃ©s GarcÃ­a-Silva",,,
Material utilizado en artÃ­culos,Efficient Inference-aware RDB2RDF Query Rewriting,"Esta pÃ¡gina proporciona acceso a los ficheros para el artÃ­culo ""Inference-aware RDB2RDF Query Rewriting"". Los enlaces son estos:
-Casos de prueba de la FAO.https://oeg.fi.upm.es/delicias.dia.fi.upm.es/~jmora/qr4rdb2rdf/fao.zip
-ComparaciÃ³n entre modos de funcionamiento en el algoritmo. https://oeg.fi.upm.es/delicias.dia.fi.upm.es/~jmora/qr4rdb2rdf/tests-table4.zip
ExplicaciÃ³n de los contenidos
Casos de prueba de la FAO
Los contenidos del archivo zip son un conjunto de casos de prueba, cada uno separado en un directorio distinto. Para cada caso de prueba se pueden encontrar los siguientes contenidos:
-El fichero de la ontologÃ­a, necesario para la inferencia.
-El fichero de los mappings, especificado en R2O.
-El fichero de los mappings expresado en una forma mÃ¡s esquemÃ¡tica, para los lectores que no estÃ©n familiarizados con R2O.
-Un fichero de comparaciÃ³n, que contiene las diferencias entre la ontologÃ­a y el fichero de los mappings. El artÃ­culo especifica el nÃºmero de conceptos, object properties y datatype properties en la ontologÃ­a, el nÃºmero de los mismos que estÃ¡n cubiertos y tambiÃ©n la cobertura como un porcentaje. La informaciÃ³n presentada aquÃ­ estÃ¡ menos procesada y es mÃ¡s detallada. En estos ficheros se enumeran los elementos que estÃ¡n presentes en sÃ³lo uno de los dos ficheros, lo que permite comprobar los elementos especÃ­ficos que causan la cobertura parcial de la ontologÃ­a por parte de los mappings y posiblemente tambiÃ©n viceversa.
ComparaciÃ³n de los modos de funcionamiento
Los contenidos del fichero zip estÃ¡n agrupados por el fichero de mappings utilizado para probar el algoritmo, Ã©se es el significado de los cuatro directorios, atlas, bcn and egm para los ficheros de mappings Atlas, BCN200 y EGM que se corresponden con Hydrontology, l directorio phenom para Phenomenontology y el Ãºnico fichero de mappings considerado para la evaluaciÃ³n con esta ontologÃ­a en el artÃ­culo En cada uno de estos directorios los contenidos son equivalentes:
-Un fichero de ontologÃ­a, Hydrontology para atlas, bcn y egm. Phenomenontology para phenom.
-Un fichero de mappings dependiendo de el directorio, uno entre Atlas, BCN200 y EGM o los mappings para Phenomenontology.
-Un fichero en texto plano con la consulta que se realiza al sistema, siempre nombrada como ""queries.txt"", la consulta es ""Q(?0) <- Aguas(?0)"" para los ejemplos con Hydrontology y ""Q(?0) <- Red(?0)"" para el ejemplo con Phenomenontology.
-Un conjunto de ficheros de texto conteniendo los resultados de la ejecuciÃ³n. Estos ficheros se corresponden con dos patrones diferentes:
-resXY.txt donde X es el modo de funcionamiento correspondiente con el sistema REQUIEM original e Y es el modo de funcionamiento correspondiente con los mÃ©todos de poda desarrollados en el contexto del artÃ­culo actual. Estos ficheros contienen la traza de ejecuciÃ³n con todas las clÃ¡usulas generadas en cada fase del algoritmo. Debido a la verbosidad para generar esta traza los tiempos de ejecuciÃ³n pueden variar ligeramente al compararlos con los tiempos descritos en el artÃ­culo.
-resRQMXY-0 donde X es el modo de funcionamiento correspondiente con el sistema REQUIEM original e Y es el modo de funcionamiento correspondiente con los mÃ©todos de poda desarrollados en el contexto del artÃ­culo actual. Los contenidos del fichero muestran la reescritura final obtenida ademÃ¡s de informaciÃ³n adicional referente al caso de prueba correspondiente.",,,
Material utilizado en artÃ­culos,Collaborative Ontology Editing Framework - Usability Survey,"Encuesta online en la siguiente pÃ¡gina.https://www.oeg-upm.net/files/UsabilitySurvey/survey.htm

GuÃ­as, ficheros de configuraciÃ³n y resultados disponibles en el siguiente enlace.https://www.oeg-upm.net/files/material/experimentData.zip

Tesis Doctoral disponible en el siguiente enlace.https://www.oeg-upm.net/files/material/dissertation-RAP-Digital.pdf",,,
Benchmarks,Federated SPARQL query benchmark,"En el grupo OEG hemos diseÃ±ado un benchmark para evaluar la nueva funcionalidad para federar consultas SPARQL propuesta por el grupo del W3C, SPARQL-WG. Este benchmark utiliza consultas que son enviadas a varios SPARQL endpoints del proyecto Bio2RDF . Estas consultas han sido diseÃ±adas en conjunto con expertos en biologÃ­a del mismo proyecto, incrementando en complejidad una query bÃ¡sica, cubriendo asÃ­ un mayor rango de consultas posibles.

Estas consultas primero acceden al SPARQL endpoint gene id, el cual contiene un conjunto de identificadores de genes. Estos identificadores los utilizamos en conjunto con los identificadores de los genes del repositorio Pubmed para obtener informaciÃ³n acerca de unos descriptores. Estos descriptores pertenecen a la taxonomÃ­a MeSH, la cual es la taxonomÃ­a base del National Library of Medicine de los EEUU. Una vez tenemos esa taxonomÃ­a podemos completar la informaciÃ³n he hemos recogido de esos 3 SPARQL endpoints y completarla con la informaciÃ³n del endpoint HHPID el cual provee interacciones entre genes y el virus HIV.
Ficheros disponibles:
-https://oeg.fi.upm.es/files/sparql-dqp/mesh.sdb.n3.zip
-https://oeg.fi.upm.es/files/sparql-dqp/ncbi.gene2pubmed.n3.zip
-https://oeg.fi.upm.es/files/sparql-dqp/pubmedai.zip
-https://oeg.fi.upm.es/files/sparql-dqp/HHPID.tar
Semantics and optimization of the SPARQL 1.1 federation extension, Carlos Buil Aranda, Marcelo Arenas, Oscar Corcho. To appear in Extended Semantic Web Conference (ESWC2011), Semantic Data Management track, 2011.",,,
