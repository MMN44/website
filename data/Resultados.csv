Resultados ;Column1;Descripcion;Enlace;Figuras;Informacion adicional
Publicaciones;;;http://oa.upm.es/cgi/search/advanced?screen=Public%3A%3AEPrintSearch&title_merge=ALL&title=&creators_name_merge=ALL&creators_name=&contributors_name_merge=ALL&contributors_name=&_fulltext__merge=ALL&_fulltext_=&abstract_merge=ALL&abstract=&keywords_merge=ALL&keywords=&subjects_merge=ALL&editors_name_merge=ALL&editors_name=&refereed=EITHER&publication_merge=ALL&publication=&event_title_merge=ALL&event_title=&note_merge=ALL&note=OEG&date=&satisfyall=ALL&order=-date%2Fcreators_name%2Ftitle&_action_search=Buscar;;
Ontologías;;;;;
Tecnologías y modelos;CIDER-CL;"CIDER-CL es un sistema para el alineamiento monolingue y multilingüe entre ontologías. Para ello utiliza varias medidas semánticas como SoftTFIDF y Cross-Lingual Explicit Semantic Analysis. El cálculo de diferentes similitudes semánticas se combina mediante el uso de redes neuronales artificiales. CIDER-CL tiene dos modos de operar:
-Alineador de ontologías: toma dos ontologías en OWL como entrada y descubre sus equivalencias, que son ofrecidas como salida en formato RDF.
-Servicio de similitud semántica: toma dos entidades ontológicas como entrada y da el valor numérico de la similitud semática entre ellos como salida. ";https://www.oeg-upm.net/files/cider-cl;;
Tecnologías y modelos;geometry2rdf;geometry2rdf es una librería para generar ficheros RDF a partir de información geométrica (que puede estar disponible en GML o WKT). La manipulación del GML y WKT se realiza con GeoTools. La version actual de la librería trabaja con bases de datos geoespaciales y se basaa en Jena. geometry2rdf ha sido desarrollado por el equipo de GeoLinked Data (.es).;https://oeg.fi.upm.es/files/geometry2rdf/geometry2rdf_bin_0.0.3.zip;https://oeg.fi.upm.es/images/stories/tecnologias/geometry2rdf.png;"Quick start
Necesitas: Java 1.5 o superior en el path (comprueba con java -version si no estás seguro)
Que hacer:
-Descargar y extraer los archivos a un directorio de trabajo.
-La distribución actual viene con un un fichero de propiedades de ejemplo.   Este fichero puede usarse como el fichero base con el que puedes empezar a trabajar.
-Ejecuta geometry2rdf desde línea de comandos.
-Espera hasta que finalice, y comprueba el fichero rdf creado.
Trabajando con el fichero de configuración
La librería necesita un fichero de propiedades para su ejecución. El nombre por defecto del fichero es options.properties. Se proporciona un fichero de pruebas con ese nombre en la distribución para us uso. Si quieres usar un fichero diferente, cambia la ruta del fichero de propiedades en el fichero bat.                                                                                                                        Estructura del fichero de propiedades:
1. Input and output parameters: Directorio de trabajo y nombre del fichero de salida.
2. DDBB parameters: Todos los parámetros necesarios para la conexión con la BBDD se configuran en esta sección. También se configuran en esta sección el nombre del tipo de recursos que se van a crear.
3. Namespaces parameters: En esta sección se indican los namespaces y prefijos para los recursos generados y para la ontología usada.
4. Reference systems parameters: Geometry2rdf funciona para sistemas de referencia EPSG. Si tus datos gml no están en EPGS, se necesita una transformación entres tu sistema de referencia y un sistema de referencia EPSG. Para ello, utiliza los campos fields gmlSourceRS y gmlTargetRS. Si se require o se desea alguna tranformación más para los datos en el fichero RDF resultante, utilice sourceRS and targetRS.
5. Types parameters: En esta sección, se definen las URIs para los recursos Point, Linestring and Polygon. También se define la URI de la relación ""formBy"". Un recurso Linestring y Polygon están ""formBy"" Points.
6. Other parameters: En esta sección, se define el lenguaje por defecto de las etiquetas de cada recurso.                                       Ejemplos de ficheros RDF de salida.
Aquí puedes consultar unos ejemplos de ficheros RDF de salida:
-Ejemplo de un recurso de tipo Municipio con geometría formada por un único punto. https://oeg.fi.upm.es/files/geometry2rdf/Point.rdf
-Ejemplo de un recurso de tipo Balsa con una geometría de tipo Linestring. https://oeg.fi.upm.es/files/geometry2rdf/Linestring.rdf
-Ejemplo de un recurso de tipo Pozo con una geometría de tipo Polygon. https://oeg.fi.upm.es/files/geometry2rdf/Polygon.rdf"
Tecnologías y modelos;gOntt;"gOntt es una herramienta para planificar y ejecutar proyectos de desarrollo cuyas principales características son las siguientes:
-Hace uso de plantillas orientadas a la planificación de desarrollos de ontologías. Estos desarrollos se basan en los escenarios propuestos por la NeOn Methodology.
-Genera las planificaciones de proyectos de desarrollo de ontologías en forma de diagramas Gantt.
-Informa a los desarrolladores de ontologías sobre cómo llevar a cabo un proceso o una actividad haciendo uso de guías metodológicas prescriptivas. También informa sobre las herramientas específicas de NeOn Toolkit que deben ser usadas.";http://neon-toolkit.org/wiki/Download;https://oeg.fi.upm.es/images/stories/tecnologias/gontt.png;"Funcionalidades de gOntt para la planificación de proyectos de desarrollo de ontologías.
gOntt ayuda a los desarrolladores de ontologías a decidir qué ciclo de vida es el más apropiado para construir sus ontologías (cascada o incremental-iterativo) así como qué procesos y actividades deben llevarse a cabo y en qué orden (por ejemplo, especificar los requisitos de la ontología antes de proceder a la transformar un recurso de conocimiento en una ontología). gOntt genera una representación gráfica de la planificación en forma de diagrama Gantt con los procesos y actividades requeridos, incluyendo las restricciones entre ellos. Las planificaciones de proyectos de desarrollo de ontologías pueden ser creadas desde cero (incluyendo procesos, actividades, fases y restricciones entre todos ellos) o de un modo guiado.
En el modo guiado, gOntt crea un plan preliminar para el desarrollo de la ontología en forma de:
-Plantillas que generan automáticamente la planificación inicial para proyectos de desarrollo de ontologías. Estas plantillas han sido construidas teniendo en cuenta la metodología NeOn. Las plantillas contienen un plan por defecto basado en las diferentes posibles combinaciones que se pueden dar entre modelos de ciclos de vida y procesos y actividades.
-Un simple asistente en dos pasos que contiene preguntas intuitivas que permiten al desarrollador de ontologías seleccionar el modelo de ciclo de vida de las ontologías y los procesos y actividades necesarias para su desarrollo. Para contestar a tales preguntas el desarrollador de ontologías ha de tener en cuenta los requisitos de la ontología y el tipo de recursos de conocimiento candidatos para ser reutilizados.
La principal salida de gOntt es el plan inicial para la construcción de la ontología en forma de diagrama Gantt que el desarrollador puede modificar con posterioridad ya sea: (a) incluyendo, modificando o borrando procesos, actividades y fases, (b) cambiando el orden y las dependencias entre procesos y actividades, e (c) incluyendo asignación de recursos y restricciones al plan. Esta funcionalidad de generar planes preliminares por defecto supone una gran ventaja sobre otras herramientas de planificación de proyectos.

Funcionalidades de gOntt para ayudar a la ejecución de proyectos
gOntt proporciona guías metodologías prescriptivas en forma de: (1) tarjetas que incluyen la definición de los procesos o actividades, sus objetivos, entradas, salidas, ejecutores de la acción y momento de la ejecución, y (2) un flujo de trabajo que describe cómo debe ser llevado a cabo el proceso o la actividad, así como sus entradas, salidas, tareas y actores involucrados. Además, gOntt proporciona un acceso directo y automatizado a las herramientas de NeOn Toolkit asociadas a cada proceso y actividad. Complementariamente, gOntt muestra una guía de comienzo rápido para cada herramienta lanzada.

Cómo utilizar gOntt
Para usar gOntt, en primer lugar, se debe instalar NeOn Toolkit (http://neon-toolkit.org/wiki/Download), y después, el plugin gOntt.En el siguiente enlace (http://www.neon-project.org/nw/Movie:_gOntt) se muestra un vídeo que muestra cómo usar gOntt."
Tecnologías y modelos;Kyrie;"Kyrie es un sistema de reescritura de consultas que usa una ontología para reescribir una consulta Datalog en otra consulta Datalog que captura el conocimiento de la ontología. La consulta reescrita obtiene extensionalmente de la fuente de datos los resultados (certain answers) que están implicados tanto extensionalmente como intensionalmente por la consulta original. En el caso de las consultas no recursivas es posible desplegar la consulta Datalog en una unión de consultas conjuntivas, la cual puede ser posteriormente transformada a SQL u otros lenguajes, con otras herramientas como Morph.
Kyrie se inició como una derivación de REQUIEM. Los objetivos para este sistema han sido:
-mejorar los tiempos de reescritura
-producir consultas más cortas cuando sea posible, puesto que deberían suponer una carga computacional menor para los sistemas que aceptan las consultas reescritas
-mantener la lógica expresiva ELHIO para la descripción de la ontología
Estos objetivos han sido satisfechos como puede verse en la evaluación.";http://j.mp/benchmarkqueryrewriting;;"Las principales publicaciones referentes a este trabajo son las siguientes:
-Mora, José and Corcho, Óscar. ""Engineering optimisations in query rewriting for OBDA"" I-SEMANTICS, 2013, 4-6 de septiembre 2013, Graz, Austria.
-Mora, J. & Corcho, O. (2013). Towards a systematic benchmarking of ontology-based query rewriting systems. The 12th International Semantic Web Conference (ISWC2013) (p./pp. 369--384), 21-26 de octubre 2013, Sydney, Australia."
Tecnologías y modelos;LabelTranslator;"LabelTranslator es un plug-in desarrollado dentro del proyecto NeOn. Este plug-in está implementado para la herramienta NeOn Toolkit y su función es la localización de los elementos , clases y propiedades, de una ontología en OWL creando un modelo repositorio lingüístico, llamado LIR por sus iniciales en inglés (Linguistic Information Repository).
El acceso multilingüe a las ontologías, hoy en día, se exige por parte de las instituciones de todo el mundo con un gran número de recursos disponibles en diferentes idiomas. Para resolver este problema, proponemos LabelTranslator, un plug-in que automáticamente localiza ontologías. LabelTranslator toma como entrada una ontología cuyas etiqueta se describen en un lenguaje natural fuente y obtiene la traducción más probable en lenguaje natural destino. En total, el plug-in soporta las siguientes funcionalidades:
-Obtiene la traducción más probable para cada etiqueta de la ontología. LabelTranslator se basa en dos módulos avanzados para esta tarea. El primer servicio, de traducción, obtiene automáticamente las diferentes traducciones posibles de una etiqueta de la ontología mediante el acceso a diferentes recursos lingüísticos. Este servicio también utiliza un método de composición con el fin de traducir las etiquetas compuestas (etiquetas formadas por varias palabras). El segundo módulo, el ranking de las traducciones, ordena las diferentes traducciones de acuerdo a la similitud con su contexto léxico y semántico. El método se basa en una medida de relación sobre la base de glosas a la ambigüedad de las traducciones. Esto se realiza mediante la comparación de los sentidos asociados a cada posible traducción y su contexto.
-Captura toda la información lingüística asociada con los conceptos utilizando un modelo lingüístico como repositorio (LIR). LIR, Repositorio de Información Lingüística, es un modelo portátil que se puede asociar a cualquiera de los términos de una ontología OWL a través de un meta-ontología OWL. Las clases principales que componen LIR (lexicalización, sentido de la definición, contexto de uso, notas y procedencia) se organizan alrededor de la clase LexicalEntry, que está vinculado a  cada término de la ontología (por medio de la relación hasLexicalEntry). El conjunto de conceptos LIR permite una completa descripción en lenguaje natural del término de la ontología al que está asociado. Además, por medio de las típicas relaciones léxicas ya sea en el mismo idioma (por ejemplo, hasSynonym) a través de idiomas (hasTranslation), LIR organiza la información lingüística en el mismo lenguaje natural y entre diferentes idiomas con el fin de proporcionar un conjunto multilingüe de información que permita la localización  de la ontología.
-Utiliza un mecanismo de sincronización para mantener la ontología y la información lingüística sincronizada. La adición de nuevos términos en la ontología o la supresión de términos existentes se controla mediante el avanzado seguimiento de cambios (basado en los recursos Delta1) utilizado en NeOn Toolkit. Este mecanismo es capaz de captar los cambios aun cuando ontológicamente hayan cambiado su posición en el modelo de la ontología. Con la adopción de esta función, LabelTranslator puede identificar con precisión el conjunto mínimo de cambios necesarios para ajustar la estructura del modelo lingüístico, un paso crítico para asegurar que un cambio importante se haga  en la ontología localizado.
Para descargar LabelTranslator, es necesario disponer de NeOn Toolkit que se puede descargar desde la página principal del proyecto NeOn Toolkit. Una vez descargada la herramienta e instalada, mediante el update site que proporciona la herramienta, podrá descargarse el plug-in LabelTranslator. La documentación de uso está disponible en la herramienta una vez descargado el plug-in e instalado.";;;
Tecnologías y modelos;LDP4j;LDP4j es un framework de código abierto basado en Java para el desarrollo de aplicaciones de lectura y escritura de Linked Data basados en la especificación Linked Data Platform 1.0 (LDP) del W3C. LDP4j proporciona los componentes requeridos por los clientes y servidores para manejar sus comunicaciones basadas en LDP, ocultando la complejidad de los detalles del protocolo de los desarrolladores de aplicaciones y dejando que se centran en el desarrollo de su lógica de negocio específica para su aplicación.;http://www.ldp4j.org/;;
Tecnologías y modelos;Lexical Model for ONtologies (lemon);Lexical Model for ONtologies (lemon) es un modelo desarrollado colaborativamente en el proyecto Monnet y concebido para ser un estándar para el intercambio de información léxica en la Web Semántica. lemon se basa en trabajo anterior de miembros de Monnet como los modelos LexInfo, LIR, y LM. El modelo lemon pretende ser un modelo: conciso, descriptivo (no prescritivo), modular, y basado en RDF.;http://lemon-model.net/;;
Tecnologías y modelos;LIR - Linguistic Information Repository;;;;
Tecnologías y modelos;map4rdf;"Recientemente, hemos visto un gran incremento en la cantidad de datos geoespaciales que están publicados utilizando RDF y los principios de Linked Data. Esfuerzos como el W3C Geo XG, y más recientemente la iniciativa GeoSPARQL están proporcionando los vocabularios necesarios para publicar este tipo de información en la Web de Datos. map4rdf es un herramienta para explorar y visualizar conjuntos de datos RDF enriquecidos con información geométrica.
map4rdf es un software open source que simplemente necesita ser configurado para usar cualquier SPARQL endpoint y que proporciona a los usuarios una visualización de datos georreferenciados y en RDF en un mapa. Los aspectos geoespaciales de los datos se pueden modelar usando o el modelo de datos del W3C Geo XG o GeoSPARQL.";http://oeg-upm.github.io/map4rdf;;https://github.com/oeg-upm/map4rdf
Tecnologías y modelos;MARiMbA;"MARiMbA es una herramienta orientada a bibliotecas para transformar sus registros en formato MARC (MAchine-ReadableCataloging) a RDF, siguiendo las mejores prácticas de Linked Data.
La herramienta soporta todo el proceso de asignación de correspondencias transformación entre los metadatos contenidos en los registros MARC y los vocabularios elegidos para generar RDF. Es una herramienta diseñada para facilitar el proceso de generación de Linked Data y permitir que sea llevado a cabo por el personal de las bibliotecas sin necesidad de asistencia técnica. Para ello, MARiMbA ofrece las siguientes características:
-Está probada para transformar registros de autoridad y bibliográficos.
-Todo el trabajo se realiza a través de hojas de cálculo, no siendo necesario conocer el manejo de ningún lenguaje de mapeo o transformación adicional (XML, XSLT, etc.)
-La herramienta realiza un análisis previo de los registros a transformar, generando las plantillas para las correspondencias a partir de dicho análisis. Dichas plantillas están enfocadas a mejorar la toma de decisiones del usuario, la identificación de errores y la evaluación del proceso de transformación.
-Permite usar cualquier vocabulario o mezcla de vocabularios en RDFS/OWL
-Incluye un fichero de configuración que permite realizar ajustes en la transformación. En cualquier caso, viene con una configuración por defecto que sigue el modelo FRBR (Functional RequirementsforBibliographicRecords).
-Incluye un servidor SPARQL ligero (Fuseki) que permite al usuario ejecutar
La herramienta ha sido utilizada con éxito para realizar la transformación a RDF de cerca de 7 millones de registros MARC 21 de la Biblioteca Nacional de España, y que ha dado como resultado alrededor de 60 millones de tripletas RDF. Los datos transformados son accesibles a través de SPARQL en http://datos.bne.es/sparql. Por otro lado, un ejemplo de uno de los registros transformados es accesible en la siguiente dirección: http://datos.bne.es/resource/XX1718747

";;;"¿Cómo utilizarlo?
Necesitas:
-Registros MARC (autoridad y/o bibliográficos) en formato ISO 2709
-Java 1.6 o superior en el path (comprueba con java -version si no estás seguro)
-Un editor de hojas de cálculo (OpenOffice, LibreOffice, Ms Excel, etc.)
Pasos:
1 Guardar/mover los ficheros MARC a transformar en la carpeta data. Poner los bibliográficos en la carpeta data/bibliographic y los de autoridad en data/authority. Se pueden transformar tantos ficheros como se desee.
2 Ejecutar el comando que genera las plantillas de mapping: ""marimba --generatemappings -a -b""   Esta acción genera 3 hojas de cálculo: classificationMapping y annotationMapping, relationsMapping. Además, crea una hoja de cálculo adicional, alias, que permite asignar alias a aquellas clases y propiedades RDF más usadas para evitar utilizar la URI completa. Las hojas de cálculo se encuentran por defecto en la carpeta mappings.
3 Utilizando las hojas de cálculo generadas, asignar correspondencias entre las combinaciones encontradas en los registros MARC y las clases y propiedades de los vocabularios elegidos. Cada hoja de cálculo tiene una función definida:
-classificationMapping: asignar la clase o tipo de recurso RDF a generar para cada una de las combinaciones.
-annotationMapping: asignar la propiedad RDF a generar a partir de cada uno de los subcampos.
-relationsMapping: asignar la relación RDF a establecer entre los recursos encontrados que presentan una determinada variación de subcampos.
4 Guardar en la carpeta models los ficheros RDF de los vocabularios utilizados. Para ello necesitas descargarlos de la Web o exportarlos a un fichero si estabas usando un editor de ontologías (como NeOnToolkit o Protégé).
5 Ejecutar el comando que genera RDF tomando las correspondencias, los registros y los vocabularios: ""marimba --generaterdf -a -b --writeresultado.rdf""
6 Si se quieren hacer consultas SPARQL directamente sobre los datos se puede ejecutar un servidor RDF ligero (Fuseki). Para ello se debe ejecutar: ""run-marimba-server""
Y en la dirección http://localhost:3030/ se pueden hacer consultas sobre los datos generados"
Tecnologías y modelos;morph;"The morph suite of technologies (together with their corresponding algorithms), is focused on applying a range of query rewriting techniques over heterogeneous federated data sources, through the use of mappings expressed in the W3C R2RML language. The suite is composed of the following languages:
- morph-RDB, for accessing relational databases. Currently it provides support for relational database management systems such as mySQL, Postgres and MonetDB. (https://oeg.fi.upm.es/index.php/es/technologies/315-morph-rdb/index.html)
- morph-LDP, an extension of morph-RDB that works with our Linked Data Platform implementation [2]. (https://oeg.fi.upm.es/index.php/es/technologies/331-morph-ldp/index.html)
-morph-GFT, for accessing Google Fusion Tables. (https://oeg.fi.upm.es/index.php/es/technologies/316-morph-gft/index.html)
-morph-streams, for accessing data streams available in Esper, GSN or SNEE, although extensible for other dynamic data sources that expose data through a REST API. (https://oeg.fi.upm.es/index.php/es/technologies/320-morph-streams/index.html)
-SPARQL-DQP, for accessing federated SPARQL endpoints. (https://oeg.fi.upm.es/index.php/es/technologies/166-sparql-dqp/index.html)
-kyrie, for enriching SPARQL queries by considering ontology entailments. (https://oeg.fi.upm.es/index.php/es/technologies/314-kyrie/index.html)";;;
Tecnologías y modelos;morph-GFT;"morph-GFT is an extension of morph-RDB that works with Google Fusion Table (GFT) tables. These tables can be described using R2RML Mappings and enables users to query them using SPARQL. In morph-GFT, SPARQL queries posed by users are translated into SQL-like queries that are supported by the GFT API.
Unlike standard relational database implementations normally used with R2RML, the GFT API does not support join operations. Therefore, the SQL-like queries that can be evaluated directly over the GFT API are rather simple. For this reason, we use SPARQL-DQP [2] to perform joins of intermediate results and then these intermediate results are translated using the R2RML mappings specified by the users. Using SPARQL-DQP brings another benefit: not only can we join the intermediate results from GFT tables, but also from other SPARQL endpoints.            [1] Applying SPARQL-DQP for Federated SPARQL Querying over Google Fusion Tables, Freddy Priyatna, Carlos Buil Aranda, Oscar Corcho. Extended Semantic Web Conference (ESWC 2013) demo track. link
[2] Semantics and optimization of the SPARQL 1.1 federation extension, Carlos Buil Aranda, Marcelo Arenas, Oscar Corcho. Extended Semantic Web Conference (ESWC2011), Semantic Data Management track, 2011. Best paper award. link";https://github.com/oeg-upm/morph-gft;https://oeg.fi.upm.es/images/architecture-morphgft.png;The morph-GFT project page is located at https://github.com/oeg-upm/morph-gft and the instructions of how to use morph-GFT can be found at https://github.com/oeg-upm/morph-gft/wiki
Tecnologías y modelos;morph-LDP;"morph-LDP[1] is an extension of morph-RDB that works with our Linked Data Platform implementation [2]. morph-LDP exposes relational data as read/write Linked Data for LDP-aware applications, whilst allowing legacy applications to continue using their relational databases.                                                                                                              [1] Mihindukulasooriya, N., Priyatna F., Corcho, O., García-Castro, R. and Esteban-Gutiérrez, M. morph-LDP: An R2RML-based Linked Data Platform implementation. The 11th Extended Semantic Web Conference 2014 Demo Session, Crete, Greece.
[2] Mihindukulasooriya, N., García-Castro, R., Esteban-Gutiérrez, M.: Linked Data Platform as a novel approach for Enterprise Application Integration. (Oct 2013)";https://oeg.fi.upm.es/images/stories/tecnologias/morph-ldp-scenario.png     https://oeg.fi.upm.es/images/stories/tecnologias/morph-ldp-1.png;;
Tecnologías y modelos;morph-RDB;"morph-RDB [1,3] (formerly called ODEMapster) is an RDB2RDF engine developed by the Ontology Engineering Group, which follows the R2RML specification (http://www.w3.org/TR/r2rml/). morph-RDB supports two operational modes:
-Data upgrade, which consists in generating RDF data from a relational database according to the R2RML mapping descriptions.
-Query translation, which allows evaluating SPARQL queries over a virtual RDF dataset, by rewriting those queries into SQL according to the R2RML mapping descriptions.
morph-RDB outperforms similar state-of-the-art tools (D2R) and query translation algorithms (e.g., the one proposed by Chebotko and colleagues in 2009) by employing various types of optimisations during the query rewriting process, so as to generate more efficient SQL queries. Some of these optimisations are self-join elimination, subquery elimination, and left-outer join elimination. morph-RDB has been tested with the BSBM synthetic benchmark and has been successfully deployed in various Spanish/EU projects (Integrate, Répener, and BizkaiSense) .
At the moment, morph-RDB works with relational database management systems like MySQL, PostgreSQL and MonetDB. In addition, morph-RDB has also been extended to support Google Fusion Tables in a project called morph-GFT [2] [6], and has been integrated with our Linked Data Platform implementation (LDP) [4] [5].
The morph-RDB project repository can be found at https://github.com/oeg-upm/morph-rdb and the instructions of how to use it can be found at https://github.com/oeg-upm/morph-rdb/wiki.

[1] Freddy Priyatna, Oscar Corcho, Juan Sequeda. Formalisation and Experiences of R2RML-based SPARQL to SQL query translation using Morph. World Wide Web Conference (WWW 2014). link
[2] Freddy Priyatna, Carlos Buil Aranda, Oscar Corcho. Applying SPARQL-DQP for Federated SPARQL Querying over Google Fusion Tables. Extended Semantic Web Conference (ESWC 2013) demo track. link
[3] Freddy Priyatna, Raul Alonso-Calvo, Sergio Paraiso, Gueton Padron-Sanchez and Oscar Corcho. R2RML-based access and querying to relational clinical data with morph-RDB. Semantic Web Applications and Tools for Life Sciences (SWAT 2015). (To appear)
[4] Mihindukulasooriya, N., García-Castro, R., Esteban-Gutiérrez, M.: Linked Data Platform as a novel approach for Enterprise Application Integration. (Oct 2013)
[5] Mihindukulasooriya, N., Priyatna F., Corcho, O., García-Castro, R. and Esteban-Gutiérrez, M. morph-LDP: An R2RML-based Linked Data Platform implementation. The 11th Extended Semantic Web Conference 2014 Demo Session, Crete, Greece.
[6] https://github.com/oeg-upm/morph-gft";https://github.com/oeg-upm/morph-rdb;;
Tecnologías y modelos;morph-streams;"morph-streams is an ontology-based data access system that allows evaluating SPARQL-Stream queries over a range of data streaming systems, which are mapped using the W3C R2RML language. More specifically, the current version of morph-streams provides wrappers for:
-The complex event processing engine Esper.
-The sensor network middleware GSN.
-The data stream management system SNEE.
Previous versions of morph-streams also supported the API of Pachube (now Xively), although this has been deprecated.
Morph-streams supports two modes of operation:
-It allows submitting SPARQL-Stream queries directly to an R2RML-wrapped data source. Queries are rewritten into the underlying query language or REST API and submitted to the underlying system, and results are then translated back using the same set of R2RML mappings.
-It allows registering SPARQL-Stream continuous queries over an R2RML-wrapped data source, to which consumers can subscribe, receiving updated results as soon as they are evaluated.
The morph-streams project repository can be found at https://github.com/oeg-upm/morph-streams, together with instructions on how to install it and use it. Besides, a live deployment of morph-streams with several types of streaming data sources can be found at http://streams.linkeddata.es/.";https://github.com/oeg-upm/morph-streams;;"An efficient RDF processing engine for heterogeneous data streams
The purpose of this research is to design and implement an engine that allows complex queries over heterogeneous data streams in near real-time at Web scale.
There is a growing number of applications that depend on the usage of real-time spatiotemporal data, and which allow moving from the usual three levels of decision making (strategic, tactical, and operational) to real-time decision making. One example would be real-time geomarketing, where decisions on offering discount coupons to customers may be made on really short time slots based on the combination of a set of spatiotemporal data streams coming from different providers, e.g. public transport card validations or weather information. Extracting information from these streams is complex because of the heterogeneity of the data, the rate of data generation, and the volume. To tap these data sources accordingly and get relevant information, scalable processing infrastructures are required, as well as approaches to allow data integration and fusion.
Our plan is to build a distributed stream processing engine capable of adapting to changing conditions while serving complex continuous queries. First, adapters for various formats are used to convert heterogeneous streams to Linked Data streams. Then, Adaptive Query Processing (AQP) allows adjusting the query execution plan to varying conditions of the data input, the incoming queries, and the system.
Our engine will address real-time processing following the Lambda principles. Lambda is a 3-layer architecture designed to alleviate the complexities of Big Data management: a batch layer stores all the incoming data in an immutable master dataset and pre-computes batch views; a serving layer indexes views on the master dataset; and a speed layer manages the real-time processing issues and requests data views depending on incoming queries. We will follow this design together with AQP techniques and RDF compressed data structures allowing to decrease access time in large datasets, as well as data transmission time among processing nodes.

 "
Tecnologías y modelos;OGSA-DAI RDF Resource;OGSA-DAI RDF Resource es una extension al sistema de acceso a datos OGSA-DAI. Esta extensión extiende OGSA-DAI añadiéndole un nuevo recurso de datos a los ya existentes en el framework (bases de datos relacionales, XML y archivos). Este nuevo recurso accede a datos en RDF almacenados en una base de datos RDF o accesibles mediante SPARQL endpoints. El acceso se realiza mediante el framework RDF Jena y Jena SDB. En la siguiente figura se muestra la extensión dentro del contexto de OGSA-DAI. Esta imagen también muestra otra extensión a OGSA-DAI, la cual accede a un sistema RDB2RDF encargado de acceder a bases de datos relacionales mediante consultas a una ontología.El nuevo recurso RDF es el encargado de configurar el acceso a los repositorios RDF. El acceso real lo realizan actividades complementarias a él. Estas actividades acceden al recurso, el cual configura los reursos de datos. Las actividades consultan posteriormente los recursos de datos y procesan los resultados de las consultas. Estos resultados son convertidos al formato interno de OGSA-DAI. Este formato son tuplas de la forma (calor1, valor2, ) y mediante este formato es posible integrar los resultados de otras consultas a otros recursos de datos de OGSA-DAI. El código del recurso puede descargarse del SVN de OGSA-DAI. Este recurso se utilice actualmente en el proyecto ADMIRE y también es utilizado por el Sciences and Technologies Facilities Council  en el Reino Unido.;http://sourceforge.net/apps/trac/ogsa-dai/;https://oeg.fi.upm.es/images/stories/tecnologias/RDFResource1.png                   https://oeg.fi.upm.es/images/stories/tecnologias/RDFResource2.png;
Tecnologías y modelos;OOPS!  OntOlogy Pitfall Scanner!;OOPS! es una aplicación web, independiente de cualquier entorno de desarrollo de ontologías, para detectar malas prácticas en ontologías que podrían, potencialmente, provocar errores en el modelado de las mismas. El objetivo de esta herramienta es ayudar a los desarrolladores de ontologías durante la actividad de validación de las mismas, la cual puede dividirse en diagnóstico y reparación. Actualmente, OOPS! proporciona mecanismos para detectar automáticamente un número de errores potenciales, ayudando por tanto a los desarrolladores durante la actividad de diagnóstico.;http://oops.linkeddata.es/;https://oeg.fi.upm.es/images/stories/oops-1.png    https://oeg.fi.upm.es/images/stories/oops-2.png;"¿Cómo usar OOPS!?
1)    Accede a http://oops.linkeddata.es/
2)    Introduce la URI de la ontología a analizar o pega el código RDF en el cuadro de texto correspondiente (Ver Figura 1) y haz click en el botón asociado a cada opción.
3)    Comprueba los resultados obtenidos (Ver Figura 2).
Contacto: oops@delicias.dia.fi.upm.es

 "
Tecnologías y modelos;Sem4Tags;"Sem4Tags es una herramienta multilingüe capaz de descubrir el significado de una etiqueta en un contexto dado y que como resultado ofrece un recurso DBpedia que define el significado de cada etiqueta procesada. La versión actual soporta etiquetas en inglés y español.
Sem4Tags identifica el significado de etiquetas multilingües asociándoles recursos DBpedia. Este proceso tiene en cuenta el contexto de la etiqueta entendido como el conjunto de las etiquetas del usuario que coocurren cuando anotan un recurso. Sem4Tags usa un repositorio de significados multilingüe (MSR por sus siglas en inglés)  creado a partir de información de la Wikipedia, donde cada palabra se relaciona con un conjunto de posibles significados que se han extraído de las páginas de desambiguación de Wikipedia.  Para seleccionar el significado más probable para una etiqueta, Sem4Tags utiliza un modelo de vectores que tiene en cuenta los términos que aparecen en cada una de las páginas Wikipedia que definen un significado.";http://grafias.dia.fi.upm.es/Sem4Tags/;;"Existe un servicio web disponible en la siguiente dirección:http://grafias.dia.fi.upm.es/SemanticTagWebServiceRestFul/resources/tag/disambiguate
Existe una aplicación on-line disponible en la siguiente dirección:http://grafias.dia.fi.upm.es/SemanticWebApp/DisambiguationTool.xhtml"
Tecnologías y modelos;sitemap4rdf;"Sitemap4rdf es una herramienta de línea de comando que genera ficheros sitemap.xml para sitios de Linked Data que tienen un SPARQL endpoint. Sitemap4rdf consulta al endpoint y recupera una lista con todas las URLs, y genera el sitemap.xml, que debe ser subido al sitio web.

Entre sus características, incluye soporte a la compresión del Sitemap, y soporte para la partición del Sitemap en varios ficheros para sitios de gran tamaño.";http://lab.linkeddata.deri.ie/2010/sitemap4rdf/;;
Tecnologías y modelos;SPARQL-DQP;"Este sistema implementa la extensión para la federación de consultas de SPARQL 1.1, extendiendo el sistema OGSA-DAI/DQP. Además, optimiza la ejecución de las consultas, trabajo realizado por SPARQL-DQP. Para ello, primero se identifican una serie de patrones bien diseñados (descritos en [1] and [2]) y si dichos patrones son identificados el sistema utiliza una serie de reglas de escritura que mejoran el tiempo de ejecución de las consultas.

[1] J. Pérez, M. Arenas and C. Gutierrez, Semantics and complexity of SPARQL, TODS 34(3), 2009
[2] Semantics and optimization of the SPARQL 1.1 federation extension, Carlos Buil Aranda, Marcelo Arenas, Oscar Corcho. Extended Semantic Web Conference (ESWC2011), Semantic Data Management track, 2011. Best paper award. https://oeg.fi.upm.es/files/pdf/eswc11paper.pdf.
[3] Federating Queries in SPARQL1.1:Syntax, Semantics and Evaluation, Carlos Buil-Aranda, Marcelo Arenas, Oscar Corcho, Axel Polleres.http://www.websemanticsjournal.org/index.php/ps/article/view/321. ";http://videolectures.net/eswc2011_corcho_extension/;;
Tecnologías y modelos;vocab-express;"Hasta ahora, los principios y buenas prácticas de Linked Data están siendo adoptadas por un número creciente de proveedores de datos, teniendo como resultado una base de datos global en la Web que contiene cientos de conjuntos de datos LOD. En este contexto es importante promover la re-utilización y enlazado de conjuntos de datos, y para este fin, es necesario conocer la estructura de los conjuntos de datos. Un primer paso para conocer la estructura de un conjunto de datos es explorar el vocabulario utilizado por el conjunto de datos, y como el conjunto de datos está utilizando ese vocabulario.
vocab-express es una herramienta simple para explorar el vocabulario utilizado en un conjunto de datos dado. La herramienta provee toda la información relacionada del vocabulario:
1 la lista de todas las clases
2 la lista de todas las properties
3 el número de instancias de cada clase
4 el número de instancias de cada property
5 el lenguaje de las etiquetas y comentarios de los elementos del vocabulario.
vocab-express está siendo implementado en node.js, que es una plataforma construida sobre V8 (Google's open source JavaScript engine) para construir aplicaciones de red rápidas y escalables. La figura muestra el flujo de información de vocab-express.";;https://oeg.fi.upm.es/images/stories/tecnologias/vocab-express.jpg;
Tecnologías antiguas;NOR2O;"NOR2O ya no está siendo utilizado, ni es mantenido por el grupo.

NOR2O es una librería para la transformación de recursos no ontológicos en ontologías. Los recursos no-ontológicos (NOR) son recursos de conocimiento cuya semántica no ha sido todavía formalizada en una ontología. Hay una gran cantidad de NORs que incorporan conocimientos sobre algunos dominios particulares y que representan algún grado de consenso.
En el contexto de la Metodología NeOn, proponemos un método general para la re-ingeniería de recursos no-ontológicos en ontologías. Se basa en  un patrón de re-ingeniería que define un procedimiento para transformar los componentes de un recurso no-ontológico en primitivas de una ontología, utilizando WordNet para desambiguar las relaciones implícitas de los componentes del NOR.
La figura 1 muestra el diagrama de arquitectura de alto nivel conceptual de los módulos implicados. El NOR connector carga los esquemas de clasificación, tesauros y lexicones con sus correspondientes modelos de datos e implementados en bases de datos, XML, ficheros de texto plano y hojas de cálculo..
El Transformer lleva a cabo la transformación propuesta por los patrones. Este módulo interactúa con el módulo Semantic Relation Disambiguator para obtener la semántica de las relaciones de los elementos NOR.
El Semantic Relation Disambiguator se encarga de obtener la semántica de las relaciones entre dos elementos NOR. Básicamente, el módulo recibe dos elementos NOR del módulo Transformer y devuelve la semántica entre ellos. El módulo conecta el recurso externo a través del módulo External Resource Service para obtener la relación.
El External Resource Service  se encarga de interactuar con los recursos externos para obtener la semántica de las relaciones entre elementos NOR. Actualmente el módulo interactúa con WordNet. Estamos implementando el acceso a DBpedia.
El OR Connector  genera la ontología en OWL Lite. Para ello, utiliza la OWL API. Finalmente, para concluir la descripción de la librería de software, conviene mencionar que la implementación de esta libraría sigue un enfoque modular, por lo tanto, es posible extenderla para incluir otros tipos de NOR, modelos de datos e implementaciones de una manera sencilla, así como la explotación de otros recursos externos para la desambiguación de relaciones.";;https://oeg.fi.upm.es/images/stories/tecnologias/nor2o.png;
Tecnologías antiguas;ODESeW;"ODESeW ya no está siendo utilizado ni mantenido por nuestro grupo.

ODESeW (Semantic Web Portal based on WebODE platform) es una aplicación basada en ontologías que genera automáticamente y gestiona portales de conocimiento para intranets y extranets. ODESeW está construido dentro de la plataforma de ingeniería de ontologías WebODE y provee las siguientes funcionalidades:
-Modela conocimiento mediante una plataforma de desarrollo de ontologías que entregra un conjunto de servicios de desarrollo de ontologías. Así como el portal de conocimiento se va a usar en la web, es altamente recomendado que use un servidor de ontologías (y no un editor de ontologías ejecutado de forma aislada) que permita construir ontologías de forma colaborativa así como dar acceso a los ontologías mediante internet. La construcción del portal sobre un servidor de ontologías facilita la sincronización de la información acorde a los cambios de las ontologías. Desde una perspectiva software, el portal se beneficia de los servicios presentes y futuros del servidor de ontologías.
-Edición e inserción de contenido mediante edición de instancias de ontologías. ODESeW permite insertar, actualizar y borrar instancias de clases, sus atributos y sus relaciones en una red de ontologías interrelacionadas y con diferentes permisos de edición para los usuarios del portal. Como parte de la edición de instancias, ODESeW puede ser utilizado como una herramienta de gestión documentacional en la que permite manejar documentos electrónicos.
-Visualización de contenido mediante visualizaciones para los usuarios de ontologías, relaciones e instancias altamente configurables. La ontologías es utilizada como índice de la información insertada y para navegar atreves de esta. El contenido almacenado en el portal puede ser accedido dinámicamente mediante minués generados por las ontologías acorde a los permisos del usuario, visualizando así las distintos tipos de información introducidos en el portal. El portal de conocimientos también provee anotación de su contenido en RDF(S), , DAML+OIL y OWL.
-Búsqueda y consultas del contenido basada en una aproximación híbrida entre ontologías y búsqueda por palabras. El modulo de búsquedas y consultas utiliza al interfaz de acceso de WebODE para acceder y consultar contenido de las ontologías.
-Servicios que facilitan la administración, que permiten gestionar los usuarios del portal, los permisos de edición y visualización, otros elementos de gestión del portal. Estos servicios puede ser solamente accedidos por aquellos usuarios que pertenecen al grupo de administración del portal.
-Como una ventaja importante de ODESeW frente a otros portales de conocimiento similares es la automática sincronización del portal y de las ontologías en las que se basa. Así, si una ontología es modificada dentro del editor de ontologías WebODE, los cambios se ven automáticamente reflejados en el portal, tanto como la conceptualización misma de la ontologías como de sus instancias.";;;
Tecnologías antiguas;OWLDoc;"OWLDoc es un plug-in desarrollado dentro del proyecto NeOn. Este plug-in está implementado para la herramiento NeOn Toolkit y su función es añadir una opción al menú de exportación de la herramienta para generar documentos HTML a partir de una ontology OWL.
El plug-in utiliza el OWL API para extrar la información de la ontología OWL y crear una salida que contiene, de manera organizada, un conjunto de ficheros HTML que proporcionan la documentación acerca de la ontología y todos sus recursos.
Para descargar OWLDoc, es necesario disponer de NeOn Toolkit que se puede descargar desde la página principal del proyecto NeOn Toolkit. Una vez descargada la herramienta e instalada, mediante el update site que proporciona la herramienta, podrá descargarse el plug-in OWLDoc. La documentación de uso está disponible en la herramienta una vez descargado el plug-in e instalado.";;;
Tecnologías antiguas;R2O y ODEMapster;"R2O & ODEMapster ya no está siendo utilizado, ni realizamos mantenimiento alguno en el grupo, puesto que ha sido reemplazado por el paquete de herramientas morph, que incluye morph-RDB, morph-GFT y morph-streams.
R2O & ODEMapster es un marco integrado para la expresión formal, la evaluación, verificación y explotación de correspondencias semánticas entre ontologías y bases de datos relacionales. El marco integrado está compuesto por:
-R2O, un lenguaje formal declarativo con expresividad suficiente como para representar situaciones de correspondencia complejas debidas al hecho de que se alinean dos modelos desarrollados y mantenidos de forma independiente y entre los que pueden darse disparidades de todo tipo.
-ODEMapster, procesador que se encarga del proceso de upgrade o enriquecimiento semántico del contenido de la base de datos o mediante la extracción bajo demanda del contenido de la base de datos en respuesta a preguntas planteadas en términos de la ontología mediante un proceso de re-escritura de consultas.
Por otro lado, ODEMapster plugin, desarrollado dentro el contexto del proyecto NeOn, proporciona una interfaz gráfica que permite crear, ejecutar o realizar consultas de ""mappings"" R2O. Este plugin está incuido en el NeOn Toolkit.
Para utilizar ODEMpaster plugin, primero hay que instalar NeOn Toolkit. NeOn Toolkit puede descargarse desde www.neon-toolkit.org. Una vez descargado, ejecute el fichero y siga las instrucciones.
Después de instalar NeOn Toolkit, el siguiente paso es instalar ODEMapster plugin. Este paso se puede realizar mediante las siguientes acciones:
1 Abrir Neon Toolkit.
2 Desde el menú Help de Neon Toolkit, elegir Software Updates --> Find and Install.
3 Una ventana Install/Update aparecerá en Neon Toolkit.
-Si ha instalado este plugin anteriormente, selecciones: Search for update
-Si no ha instalado este plugin anteriormente, seleccione: Search for new features
-Seleccione Neon Toolkit Update Site entre los posibles sitios de actualización y pulse finish
-Seleccione ODEMapster dentro de Ontology Population y presione next
-Seleccione Agree en el acuerdo de licencia.
-Pulse Finish en la ventana de instalación..
Para una información más completa, consulte el manual de ODEMapster. http://geo.linkeddata.es/c/document_library/get_file?uuid=2a944333-4cd6-4ff1-aaab-68f62fbf0d3c&groupId=10136
 ¿Cómo funciona?
Para la ontología hydrOntology y cada una de las bases de datos del IGN se creó un documento R2O que describe los mappings entre cada base de datos y la ontología. A continuación, se ejecutó el procesador ODEMapster para generar las instancias RDF.  Las bases de datos del IGN están almacenadas en MySQL y ORACLE e hydrOntology está en OWL.";;https://oeg.fi.upm.es/images/stories/odemapsterprocess.png   https://oeg.fi.upm.es/images/stories/igndatasets.png;"Lista de usuarios de ODEMapster
FAO - http://fao.org
Guntars Bumars - University of Latvia - Institute of Mathematics and Computer Science - http://www.lumii.lv/Pages/computer.htm
Christian M. Fletcher - Department of Computer Science - Durham University - http://www.dur.ac.uk/ecs/computing.science/undergraduate09/whatis/
iSOCO - www.isoco.com
GIS4GOV project
SemSorGrid4Env - http://www.semsorgrid4env.eu/
GeoLinkedData - http://geo.linkeddata.es/
WEB n+1 - http://www.webenemasuno.es"
Tecnologías antiguas;WebODE;"WebODE ya no está siendo utilizado ni mantenido por nuestro grupo desde 2006.

WebODE es un suite extensible de ingeniería de ontologías basada en un servidor de aplicaciones que empezó en 1999. El núcleo de WebODE es su servicio de acceso a sus ontologías, utilizado por todos los demás servicios y aplicación acopladas al servidor. El editor de ontologías WebODE permite editar y navegar por las ontologías, y esta basada en formularios HTML y applets de Java.

WebODE fue construido como una plataforma escalable, extensible e integrada que cubre y da soporte a la mayoría de las actividades involucradas en el proceso de desarrollo de ontologías (conceptualización, razonamiento, intercambio, etc.) y provee un conjunto de servicios relaciones a las ontologías que permite interoperar con otros sistemas de información. Entre estos servicios, la plataforma integra servicios para la importación y exportación de lenguajes de ontologías (XML, RDF(S), OIL, DAML+OIL, OWL, CARIN, FLogic, Jess, Prolog), para la edición de axiomas mediante WAB (WebODE Axiom Builder), para generar documentación, para evaluar, para controlar la evolución, para extraer ontologías, para juntarlas y un motor de inferencia.

La publicación más relevante es Most relevant publications:

WebODE in a nutshell. AI Magazine 2003.";;https://oeg.fi.upm.es/images/stories/tecnologias/webode.png;
Tecnologías antiguas;WS-DAIOnt-RDF(S);"WS-DAIOnt-RDF(S) ya no está siendo utilizado ni mantenido por nuestro grupo.

WS-DAIOnt-RDF(S) es una especificación que define un mecanismo de acceso a ontologías RDF(S) utilizando una aproximación orientada a servicios. Esta especificación, compatible con la arquitectura OGSA, define el conjunto de recursos de datos, mensajes e interfaces de acceso necesarios para la integración de ontologías en RDF (S) en cualquier aplicación (Grid) orientada a servicios.  RDF(S) Grid Access Bridge  (RGAB) es la implementación de referencia de dicha especificación. Esta implementación desacopla el mecanismo de acceso de la ubicación física real de las ontologías RDF(S) así como del sistema de almacenamiento utilizado para su persistencia.
De esta forma, las ontologías RDF (S) pueden ser almacenadas en un conjunto distribuido de sistemas de almacenamiento de RDF (S) y hacerse accesibles mediante los mecanismos de acceso definidos por la especificación WS-DAIOnt-RDF (S).";;;
Servicios;esDBpedia;"DBpedia ocupa un lugar central  en la Web de Datos por el importante volumen de datos semánticos que proporciona a partir de la información contenida en los infoboxes (Fichas en español) de la Wikipedia del idioma inglés. La última versión de DBpedia (v3.9, septiembre de 2013) proporciona datos semánticos de 4 millones de entidades, de las que 3.2 millones están clasificadas conforme a la ontología DBpedia: Personas (832 mil),  Lugares (639 mil), Discos musicales (116 mil), y un largo etcétera (529 claes y 2333 propiedades).
A partir de los 30 millones de artículos en 240 idiomas que almacena Wikipedia (4.4 millones en inglés, 1.1 millones en español), DBpedia genera 2460 millones datos semánticos (tripletas RDF) en 119 idiomas (470 millones en inglés, y 100 millones en español).
Hasta julio de 2011 (versiones DBpedia anteriores a la v3.7), sólo se extraía información de una página en español de la Wikipedia si se apuntaba a ella desde la versión inglesa. Por tanto, muchas páginas con información local relevante (e.g. pueblos, ríos, organizaciones) a la que no se podía llegar desde la versión inglesa de Wikipedia, quedaban fuera del proceso de extracción de DBpedia. En julio de 2011, la versión 3.7 de DBpedia se construyó usando un nuevo mecanismo de extracción que rompía con la dependencia de la versión inglesa de Wikipedia, permitiendo generar, adicionalmente, información semántica a partir de las versiones de Wikipedia en 15 idiomas, entre ellos el español (ca, de, el, es , fr, ga, hr, hu, it, nl, pl, pt, ru, sl, tr). La versión 3.8 de DBpedia (junio 2012) amplió la lista de idiomas a 111, y la versión actual (3.9) llegó a los 119 idiomas.

Jornadas de mapeos
Sin embargo, para que la Web de Datos se enriquezca con la información contenida en la versión española de la Wikipedia, es necesario un esfuerzo colectivo importante a fin de aumentar el número de mapeos de Fichas. DBpedia pone a disposición de la comunidad herramientas web para editar estos mapeos en los que se indica la correspondencia entre términos de las Fichas y los términos de la ontología de DBpedia. La I Jornada esDBpedia  logró mapear el 80% de los datos de la wikipedia del idioma español y permitió la creación de es.dbpedia.org, el capítulo español de DBpedia en mayo de 2012. La II edición de las jornadas (diciembre de 2012) se centró en mejorar la calidad de los mapeos.";;;
Metodologías;La Metodología NeOn;"La Metodología NeOn para la construcción de redes de ontologías es una metodología basada en escenarios que se apoya en los aspectos de colaboración de desarrollo de ontologías y la reutilización, así como en la evolución dinámica de las redes de ontologías en entornos distribuidos. Las claves de la Metodología NeOn son:
-Un conjunto de nueve escenarios para la construcción de ontologías y redes de ontologías, haciendo hincapié en la reutilización de los recursos ontológicos y no ontológicos, la reingeniería y la fusión, y teniendo en cuenta la colaboración y el dinamismo.
-El Glosario de Procesos y Actividades identifica y define aquellos procesos y actividades involucrados en el desarrollo de redes de ontologías.
-Directrices metodológicas para diferentes procesos y actividades del proceso de desarrollo de la ontología de la red, tales como la reutilización y la reingeniería de los recursos ontológicos y no ontológicos, la especificación de los requisitos de la ontología, la localización de la ontología, la programación, etc. Todos los procesos y actividades se describen con (a) una tarjeta llena, (b) un flujo de trabajo, y (c) ejemplos.

Escenario 1: Desde la especificación de la aplicación. La red de ontologías se desarrolla a partir de cero (sin volver a utilizar los recursos existentes). Los desarrolladores deben especificar los requisitos de la ontología (enlace a las directrices). Después de eso, se asesora para llevar a cabo una búsqueda de recursos potenciales para ser reutilizados. A continuación, la actividad de planificación se debe realizar (enlace a las directrices), y los desarrolladores deben seguir el plan.
Escenario 2: La reutilización y reingeniería de los recursos no ontológicosc (NOR). Los desarrolladores deben llevar a cabo el proceso de reutilización NOR para decidir, de acuerdo con los requisitos de la ontología, que NORs pueden ser reutilizados para construir la red de la ontología. A continuación, los NORs seleccionados deben ser volver al proceso de re-ingeniería ontológicas. Las directrices se presentan en el enlace de directrices.
Escenario 3: La reutilización de los recursos ontológicos. Los desarrolladores utilizan recursos ontológicos (ontologías como un conjunto de módulos ontológicos (enlace a las directrices enlace 1, enlace 2), y / o declaraciones ontológicas (enlace a las directrices)) para construir redes de ontologías.
Escenario 4: La reutilización y re-ingeniería de los recursos ontológicos. Los desarrolladores de ontologías reutilizan los recursos y reorganizar los recursos  ontológicos.
Escenario 5: La reutilización y la fusión de los recursos ontológicos. Este escenario se produce cuando varios recursos ontológicos en el mismo dominio que se seleccionan para su reutilización, y los desarrolladores desean crear un nuevo recurso ontológico con los recursos seleccionados. Las directrices se presentan en el enlace de directrices.
Escenario 6: Reutilización, la fusión y re-ingeniería de los recursos ontológicos. Los desarrolladores de ontologías reutilizan, combinan y reorganizan los recursos-ontológicos. Este escenario es similar al Escenario 5, pero en este caso los desarrolladores deciden reorganizar el conjunto de recursos combinados.
Escenario 7: Reutilización de los patrones de diseño de ontologías (ODPs). Los desarrolladores de ontologías acceden a repositorios de reutilización ODPs.
Escenario 8: Reestructuración de recursos ontológicos. Los desarrolladores de ontologías reestructuran (modularizan, podan, extienden y / o especializan) recursos ontológicos que deben integrarse posteriormente en la red de ontologías.
Escenario 9: Localización de recursos ontológicos. Los desarrolladores de ontologías adaptan una ontología a otras lenguas y la cultura las comunidades, obteniendo así una ontología multilingüe. Las directrices se presentan en el enlace de directrices.";http://oa.upm.es/3879/;https://oeg.fi.upm.es/images/stories/tecnologias/neonmethodology.png;
Linked data;LinkedData.es;LinkedData(.es) es una sitio web en el que se pueden consultar, de una manera rápida, las iniciativas, proyectos, colaboraciones y aplicaciones desarrolladas por el grupo en el ámbito de los Datos Enlazados. Como se puede observar, el grupo ha desarrollado y sigue desarrollando trabajos en diferentes dominios (geográfico, cultural, datos abiertos etc) tanto con instituciones públicas (BNE, RTVE, IGN, etc) como con empresas privadas (Grupo PRISA). También nos encargamos de la DBpedia en español, esDBpedia. ;http://linkeddata.es/;;
Linked data;GeoLinked Data;"GeoLinked Data (.es) es una iniciativa para el enriquecimiento de la Web de los Datos con datos geoespaciales del territorio nacional español. Esta iniciativa se puso en marcha en el año 2008 con la publicación de diversas fuentes de información geográfica procedentes del Instituto Geográfico Nacional español, haciéndolas disponibles como bases de conocimiento RDF (Resource Description Framework) conforme a los principios de Linked Data.
De esta manera, España se sumaba en dicho momento a la iniciativa que otros países como el Reino Unido habían comenzado también.
Algunos de los productos que se obtuvieron como resultado de este trabajo fueron los siguientes:
-geometry2rdf, una librería para la generación de RDF geográfico. Esta librería fue utilizada como base para la generación de la librería TripleGeo, que se ha utilizado para la generación de RDF geográfico de un gran número de fuentes de datos geográficas europeas.
-map4RDF, para la visualización de datos geográficos enlazados, disponibles en un punto de acceso SPARQL.
Desde entonces, desde nuestro grupo hemos continuado trabajando en la mejora de estas herramientas, con el objetivo de ofrecer un conjunto de sistemas que puedan ser utilizados para la generación de RDF geográfico, de acuerdo con las lecciones aprendidas por la comunidad internacional en estos primeros pasos, así como teniendo en cuenta los principales resultados del grupo de trabajo del W3C sobre Spatial Data on the Web.
Así, hemos trabajado en crear un plugin para GeoKettle que hace uso y extiende la librería TripleGeo, y en estos momentos (año 2017), estamos trabajando en la reedición de una nueva versión del portal de datos geográficos y de Linked Data Geográfico, basado en la base de datos BTN100, que incorpora todos estos avances realizados en los últimos años. La descripción de este portal se actualizará una vez que se haya desplegado esta nueva versión a finales del año 2017.";;;
Material utilizado en artículos;Detecting common scientific workflow fragments using templates and execution provenance;"La evaluación del artículo ""Detecting common scientific workflow fragments using templates and execution provenance"" aceptado en K-CAP 2013 se encuentra disponible en el siguiente link. Los datos expuestos consisten en los grafos que se han utilizado como entrada para el experimento (derivados del SPARQL endpoint público de Wings), los resultados y logs obtenidos por el algoritmo SUBDUE durante su ejecución y algunas estadísticas y hojas excel resumiendo dichos resultados (por ejemplo, destacando el  número de estructuras que son independientes, contando aquellas que son relevantes, etc.).

Si está interesado en obtener más información puede leer el siguiente artículo: Daniel Garijo, Oscar Corcho y Yolanda Gil. Detecting common scientific workflow fragments using templates and execution provenance. K-CAp 2013, Banf, Canada.";https://www.oeg-upm.net/files/dgarijo/kcap2013Eval;;
Material utilizado en artículos;Semantic Grounding of Tags (sem4tags);Se publican los datos de la evaluación de las asociaciones de entidades semánticas producidas por sem4tags y sus variaciones para las etiquetas extraídas de Flickr (link a conjunto de datos).  Las evaluaciones están en un archivo CSV donde los diferentes campos que componen la evaluación están separados por el carácter |. Cada fila en este archivo representa una evaluación individual de la asociación de una entidad semántica a una etiqueta. Recuerde que cada asociación semántica fue evaluada por al menos tres evaluadores. Finalmente, se recomienda leer el archivo readme donde se explica en detalle cada uno de los atributos que describen cada evaluación. Para cualquier duda acerca de este conjunto de datos se puede contactar a Andrés García-Silva;;;
Material utilizado en artículos;Characterising Emergent Semantics in Twitter Lists;"El siguiente conjunto de datos contiene los datos de las listas de Twitter que han sido utilizados en los experimentos presentados en el artículo ""Characterising Emergent Semantics in Twitter Lists"" del 9th Extended Semantic Web Conference (ESWC 2012). Los datos se encuentran en una archivo de respaldo de una base de datos mysql version 5.5.14 que contiene información de las listas y de los distintos tipos de usuarios que interactúan con ellas. Además hemos incluido un diagrama entidad relación que representan las tablas que contienen la información.
Por favor si usted usa este conjunto de datos cite la siguiente referencia: García-Silva A., Kang J.H., Lerman K and Corcho O. Characterising Emergent Semantics in Twitter Lists. In proceedings of the 9th extended Semantic Web Conference ESWC, Crete, 2012.
Para preguntas sobre el conjunto de dato, contacte con: Andrés García-Silva";;;
Material utilizado en artículos;Efficient Inference-aware RDB2RDF Query Rewriting;"Esta página proporciona acceso a los ficheros para el artículo ""Inference-aware RDB2RDF Query Rewriting"". Los enlaces son estos:
-Casos de prueba de la FAO.https://oeg.fi.upm.es/delicias.dia.fi.upm.es/~jmora/qr4rdb2rdf/fao.zip
-Comparación entre modos de funcionamiento en el algoritmo. https://oeg.fi.upm.es/delicias.dia.fi.upm.es/~jmora/qr4rdb2rdf/tests-table4.zip
Explicación de los contenidos
Casos de prueba de la FAO
Los contenidos del archivo zip son un conjunto de casos de prueba, cada uno separado en un directorio distinto. Para cada caso de prueba se pueden encontrar los siguientes contenidos:
-El fichero de la ontología, necesario para la inferencia.
-El fichero de los mappings, especificado en R2O.
-El fichero de los mappings expresado en una forma más esquemática, para los lectores que no estén familiarizados con R2O.
-Un fichero de comparación, que contiene las diferencias entre la ontología y el fichero de los mappings. El artículo especifica el número de conceptos, object properties y datatype properties en la ontología, el número de los mismos que están cubiertos y también la cobertura como un porcentaje. La información presentada aquí está menos procesada y es más detallada. En estos ficheros se enumeran los elementos que están presentes en sólo uno de los dos ficheros, lo que permite comprobar los elementos específicos que causan la cobertura parcial de la ontología por parte de los mappings y posiblemente también viceversa.
Comparación de los modos de funcionamiento
Los contenidos del fichero zip están agrupados por el fichero de mappings utilizado para probar el algoritmo, ése es el significado de los cuatro directorios, atlas, bcn and egm para los ficheros de mappings Atlas, BCN200 y EGM que se corresponden con Hydrontology, l directorio phenom para Phenomenontology y el único fichero de mappings considerado para la evaluación con esta ontología en el artículo En cada uno de estos directorios los contenidos son equivalentes:
-Un fichero de ontología, Hydrontology para atlas, bcn y egm. Phenomenontology para phenom.
-Un fichero de mappings dependiendo de el directorio, uno entre Atlas, BCN200 y EGM o los mappings para Phenomenontology.
-Un fichero en texto plano con la consulta que se realiza al sistema, siempre nombrada como ""queries.txt"", la consulta es ""Q(?0) <- Aguas(?0)"" para los ejemplos con Hydrontology y ""Q(?0) <- Red(?0)"" para el ejemplo con Phenomenontology.
-Un conjunto de ficheros de texto conteniendo los resultados de la ejecución. Estos ficheros se corresponden con dos patrones diferentes:
-resXY.txt donde X es el modo de funcionamiento correspondiente con el sistema REQUIEM original e Y es el modo de funcionamiento correspondiente con los métodos de poda desarrollados en el contexto del artículo actual. Estos ficheros contienen la traza de ejecución con todas las cláusulas generadas en cada fase del algoritmo. Debido a la verbosidad para generar esta traza los tiempos de ejecución pueden variar ligeramente al compararlos con los tiempos descritos en el artículo.
-resRQMXY-0 donde X es el modo de funcionamiento correspondiente con el sistema REQUIEM original e Y es el modo de funcionamiento correspondiente con los métodos de poda desarrollados en el contexto del artículo actual. Los contenidos del fichero muestran la reescritura final obtenida además de información adicional referente al caso de prueba correspondiente.";;;
Material utilizado en artículos;Collaborative Ontology Editing Framework - Usability Survey;"Encuesta online en la siguiente página.https://www.oeg-upm.net/files/UsabilitySurvey/survey.htm

Guías, ficheros de configuración y resultados disponibles en el siguiente enlace.https://www.oeg-upm.net/files/material/experimentData.zip

Tesis Doctoral disponible en el siguiente enlace.https://www.oeg-upm.net/files/material/dissertation-RAP-Digital.pdf";;;
Benchmarks;Federated SPARQL query benchmark;"En el grupo OEG hemos diseñado un benchmark para evaluar la nueva funcionalidad para federar consultas SPARQL propuesta por el grupo del W3C, SPARQL-WG. Este benchmark utiliza consultas que son enviadas a varios SPARQL endpoints del proyecto Bio2RDF . Estas consultas han sido diseñadas en conjunto con expertos en biología del mismo proyecto, incrementando en complejidad una query básica, cubriendo así un mayor rango de consultas posibles.

Estas consultas primero acceden al SPARQL endpoint gene id, el cual contiene un conjunto de identificadores de genes. Estos identificadores los utilizamos en conjunto con los identificadores de los genes del repositorio Pubmed para obtener información acerca de unos descriptores. Estos descriptores pertenecen a la taxonomía MeSH, la cual es la taxonomía base del National Library of Medicine de los EEUU. Una vez tenemos esa taxonomía podemos completar la información he hemos recogido de esos 3 SPARQL endpoints y completarla con la información del endpoint HHPID el cual provee interacciones entre genes y el virus HIV.
Ficheros disponibles:
-https://oeg.fi.upm.es/files/sparql-dqp/mesh.sdb.n3.zip
-https://oeg.fi.upm.es/files/sparql-dqp/ncbi.gene2pubmed.n3.zip
-https://oeg.fi.upm.es/files/sparql-dqp/pubmedai.zip
-https://oeg.fi.upm.es/files/sparql-dqp/HHPID.tar
Semantics and optimization of the SPARQL 1.1 federation extension, Carlos Buil Aranda, Marcelo Arenas, Oscar Corcho. To appear in Extended Semantic Web Conference (ESWC2011), Semantic Data Management track, 2011.";;;
